<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: redshift | Continuous Ops]]></title>
  <link href="http://chokkoyamada.github.io/blog/categories/redshift/atom.xml" rel="self"/>
  <link href="http://chokkoyamada.github.io/"/>
  <updated>2014-07-18T14:59:53+09:00</updated>
  <id>http://chokkoyamada.github.io/</id>
  <author>
    <name><![CDATA[Naoyuki Yamada]]></name>
    <email><![CDATA[yamada_naoyuki@cyberagent.co.jp]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: Amazon Redshiftによるリアルタイム分析サービスの構築]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad/"/>
    <updated>2014-07-17T13:08:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad</id>
    <content type="html"><![CDATA[<p>Cookpadのエンジニアの青木さんによる、Redshiftの活用方法です。　</p>

<p>さきほどのEMRのセッションも聞きつつも、SQLの世界は深いので、まだまだSQLで頑張れる部分はたくさんあるのではないかと思っています。
Redshiftで可能なことのごく一部しか使っておらず、「Redshiftじゃきつい」というレベルにもまだないです。</p>

<p>ただ、いうほど”リアルタイム”ではなかったです。ユーザーからの検索はリアルタイムで直接SELECTしているみたいですが、データ更新はバッチ処理でした。</p>

<p>User &ndash; EC2 &ndash; Redshiftという構成になっているのが一番驚きました。「たべみる」がB2Bサービスなのでそれほど同時に使う人数が多くないのでしょうが、こういう構成は無理かなと思い込んでいたのでとても参考になりました。</p>

<h2>たべみる: 検索システム</h2>

<ul>
<li>単語の検索頻度</li>
<li>単語の組み合わせ頻度</li>
<li>現在盛り上がっている単語</li>
<li>ユーザーの年代や居住地域を軸とした分析</li>
</ul>


<p>「バレンタイン」のキーワード分析　単語の組み合わせ　マッチ度　バレンタイン + 本命, 簡単, 大量</p>

<h2>たべみるのシステム構成</h2>

<p>User &ndash; ELB &ndash; EC2 &ndash; Redshift</p>

<p>Rails4 / Ruby2.1
dw2.large x 12</p>

<p>目標応答時間 500msec</p>

<p>応答速度向上の施策
圧縮タイプの選択
sort key: where句で入れているものは全てSort Keyに入れる 大きく削るならDist Key, 細かいチューニングはSort key
サマリーテーブル: 大きいデータをクエリすると絶対に時間かかるので、サマっておく</p>

<p>サマリーテーブルいつ作る？
安心と伝統の夜間バッチ 37minで実行できているのでHourlyの更新も可能だが、あえてやっていない。不要なので。
B2Bサービスなので、1日に少しずつ追加されてもあまり意味が無いため。</p>

<p>ログまたはMySQL &ndash;> file &ndash;> Redhisft(raw &ndash;> 中間データ &ndash;> summaryの三段階)</p>

<h2>データ連携の詳細</h2>

<p>信頼と実績のTSV渡し</p>

<p>他の用途ではfluentdによる継続ロードも</p>

<h2>SQLによるデータ処理</h2>

<ul>
<li><p>ELTのお約束</p>

<ul>
<li>エクスポート禁止:　データ移動は遅い　 DB外処理は非並列</li>
<li>UPDATE禁止:  複数回実行しにくい(冪等にしておきたい) VACUUMが厄介</li>
<li>1行INSERT禁止:  COPYかINSERT SELECT</li>
</ul>
</li>
<li><p>INSERT SELECTだけ使え！！</p></li>
<li><p>SQLでは書けなかった処理</p>

<ul>
<li>日本語処理　半角→全角変換</li>
<li>可変数カラム　タブ区切り文字列の分割</li>
<li>要するに文字列処理がきつい</li>
</ul>
</li>
<li><p>SQLで書ける！ こんな処理</p>

<ul>
<li>単語の組み合わせ生成  ジョイン</li>
<li>未来の月曜日N週ぶんの生成 ジョイン</li>
<li>テーブルの縦横変換 ジョイン</li>
<li>移動平均、移動累積和 ウィンドウ関数</li>
<li>グループごとのランキングTOPN ウィンドウ関数</li>
</ul>
</li>
<li><p>テーブルの縦横変換の例</p></li>
<li>グループごとのランキングの例 ウィンドウ関数を使うと、分割するけど、これを集約せずに結果だけ取ることができる

<ul>
<li>rank() over ( partition by ~ order by ~)</li>
</ul>
</li>
</ul>


<h2>データ更新のパターン</h2>

<ul>
<li><p>差分更新</p>

<ul>
<li>追加されたデータだけ更新する</li>
<li>デメリットは、冪等にしくくいこと</li>
<li>そのため、あらかじめ生成されるレンジのデータを消してからデータを挿入する処理にする</li>
</ul>
</li>
<li><p>洗い替え</p>

<ul>
<li>dropまたはtruncateして作りなおす</li>
<li>差分を考える必要がない</li>
<li>遅い</li>
<li>新しいテーブルを作ると権限(GRANT)を1個1個つけて回る必要があり、面倒</li>
<li>VACUUM問題</li>
</ul>
</li>
<li><p>アトミック洗い替え</p>

<ul>
<li>新しいテーブルを作ってる途中にテーブルが無くなってしまうので、テーブルが作り終わってからTRANSACTION内でALTER TABLE RENAMEする</li>
<li>24時間参照するテーブルではこれを使う</li>
<li>デメリットとしては、データが2倍になってしまう</li>
</ul>
</li>
<li><p>応用：アトミックな本番切り替え</p>

<ul>
<li>複数のテーブルをいっぺんに切り替える</li>
<li>複数のテーブルがお互いにデータが関連している場合</li>
</ul>
</li>
<li><p>更新パターンの使い分け</p>

<ul>
<li>生データは差分更新</li>
<li>中間データは洗い替え</li>
<li>サマリーデータはアトミック洗い替え</li>
</ul>
</li>
</ul>


<h2>なぜRedshiftにしたのか</h2>

<ul>
<li>COOKPADがAWSにあるから</li>
<li>マネージドサービスだから</li>
<li>並列処理能力が高いから</li>
<li>ウィンドウ関数など高度な機能が実装されているから</li>
<li>ある程度オンライン処理にも耐えられるから</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2013(1) Redshiftのパフォーマンスと使いどころ]]></title>
    <link href="http://chokkoyamada.github.io/blog/2013/06/06/aws-summit-2013/"/>
    <updated>2013-06-06T13:25:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2013/06/06/aws-summit-2013</id>
    <content type="html"><![CDATA[<p>AWS Summit Tokyo 2013の中から2セッション、まとめておきたいと思います。1つめはRedshiftに関するセッションです。</p>

<p>セッション紹介 ｜ AWS Summit Tokyo 2013  <br/>
<a href="http://www.awssummittokyo.com/session.html#Tech-05">「Amazon Redshiftが切り開くクラウド・データウェアハウス」</a></p>

<p>私の勤務する<a href="http://aws.amazon.com/jp/about-aws/whats-new/2013/6/5/Amazon-Redshift-and-High-Storage-Instance-in-Tokyo-Region/">AMoAdでは、RedShiftがUS-Eastリージョンで使えるようになって以来注目していて、実際に本番環境で使ってきました。</a> 私は中心的にRedshiftをじっくり使ってきたわけではないのですが、運用担当として興味深く聴講しました。</p>

<h2>Redshiftの概要</h2>

<pre><code>エンタープライズシステムにおける活用ノウハウ

Amazon Redshiftの取り組みについて

クラウド型データウェアハウス
オンプレ環境におけるデータウェアハウスの課題
・初期投資
・運用管理
・成長予測・費用対効果

install backupなどのルーチンワークをAWSに任せて、codingとperformance tuningに割く時間を増やせる

RDS, DynamoDBなどのオンライントランザクション→ EMR, S3→Redshift

カラムナ型データベース
列が多いケースにはパフォーマンスの向上が見られやすい

* Leader Node クエリのパース・分析をしてC++コードを生成してcompute nodeに投げる

* compute nodes ここを増やすことで器を大きくできる

    1.6PBまで拡張可能

JDBCのPostgreSQLドライバを使える

AmazonS3かDynamoDBからの並列ロード

S3への自動バックアップ・増分バックアップ・オンデマンドのバックアップ　
リサイズする場合：新しいクラスタをバックグラウンドでプロビジョニング
ノード数×時間単価の課金　

日本ではデータウェアハウスとOLTPの中間的な使い方をしている場合が多い　
</code></pre>

<p>まずはRedshiftの概要の説明です。Redshiftはすでに基本的なところは調べて実際に使ってきたのでほとんどが既知の事項でした。</p>

<p>エンタープライズ向けを主に意識しているセッションだけあって聞き慣れない単語がいくつかありましたが・・・そもそもRedshiftは個人で気軽に試すには若干値が張る（最小構成でも1ノードを1ヶ月フルで使うと$0.85 x 24hour x 30dayで6万円程度）</p>

<pre><code>## Redshiftの性能は？

他と比較するとSEの寿命が縮まるので・・・

### 巨大テーブルからの検索処理

1.5TBくらいのデータの検索結果  500億件
8XL 2node 43.5sec
8XL 4node 27.8sec
8XL 8node 19.8sec

線形に性能が向上しているのに驚いた

### データロードのスピード 500億件

8XL 2node 2:54sec
8XL 4node 1:37
8XL 8node 0:46

### 1.2億件の検索結果

8XL 2node 3.30 sec
8XL 4node 1.40 sec
8XL 8node 1.80 sec

## バッチ処理は？

EMRとの比較
1.5TB, 500億件

EMR 29min
Redshift 17min

EMR 71min
Redshift 5min

チューニングのポイント
キー(index)

distribution keyに応じてスライスに配置される
sort keyをもとにレコードがソートされる

### チューニング効果
* 1.2億件

指定無しは1.8秒
指定ありは1秒

* バッチ処理

指定あり：24min
指定無し：16min

sort keyを入れるとロードは遅くなるので注意

### コスト:w
128coe 960gb 128tb storage
構築費はほぼ不要、維持管理のSEも不要、センター費用は不要

### 注意点は？
不得意なデータ形式もある
EMRで前処理

簡単につくれてしまうため、統制のきいていないシステムの乱立に注意

### まとめ

* 性能は線形にスケール
* バッチ処理も得意
* チューニングは新しい概念で
* 利用料課金はメリット大
* 注意点もある
</code></pre>

<p>次は野村総研の方からの検証結果報告です。データのSELECTが早いのは確かだと思います。ただ、セッションでも言及されているように、「不得意なデータ形式もある」ということで、結局のところRedshiftのポテンシャルをフルに引き出して使いこなすには、時間とともに溜まるノウハウの蓄積が欠かせない気がします。</p>

<p>データのロードについても同様で、<a href="http://www.hapyrus.com/products/flydata-for-redshift">FlyData for Amazon Redshift</a>というサービスがあるくらい、Redshiftに適切な速度で要領よくデータをアップロードするのは難しいという印象です。このへんも各所で検証が進むにつれて、うまいやり方というのが見いだされてくるのかなと思います。</p>
]]></content>
  </entry>
  
</feed>
