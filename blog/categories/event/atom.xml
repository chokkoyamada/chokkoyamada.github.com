<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: event | Continuous Ops]]></title>
  <link href="http://chokkoyamada.github.io/blog/categories/event/atom.xml" rel="self"/>
  <link href="http://chokkoyamada.github.io/"/>
  <updated>2014-07-18T16:57:59+09:00</updated>
  <id>http://chokkoyamada.github.io/</id>
  <author>
    <name><![CDATA[Naoyuki Yamada]]></name>
    <email><![CDATA[yamada_naoyuki@cyberagent.co.jp]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Dell主催「次世代ネットサービス向け クラウド・インフラストラクチャ セミナー」- プライベートクラウドについて考える]]></title>
    <link href="http://chokkoyamada.github.io/blog/2013/06/21/dell-infra-seminar/"/>
    <updated>2013-06-21T14:56:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2013/06/21/dell-infra-seminar</id>
    <content type="html"><![CDATA[<p>2013/06/21 15:00~18:00、<a href="http://www.event-reg.jp/dell/sem130621/">デル株式会社主催『次世代ネットサービス向け クラウド・インフラストラクチャ セミナー』</a>というセミナーが行われたので参加しました。Dellもクラウドのセミナーをやるようになったとは時代の流れを感じます。</p>

<p>前半2つのセッションはほとんど聴いていなかったので、後半2つのセッションについて書き留めておきます。</p>

<h2>『WEBサービスに最適なクラウド基盤を構成する３つの要素』(クリエーションライン：安田さん)</h2>

<p><a href="http://www.creationline.com">クリエーションライン</a> という会社、Opscode Chefの日本の正規代理店という点で名前だけは知っていましたが、今回はじめて具体的に業務内容を知りました。</p>

<p>クラウドの導入支援やコンサルティングをしている会社なんですね。OpenStack周りでコミュニティとも関わりの強い会社のようです。</p>

<p>タイトルにある3つの要素とは、下記の3点のことで、ぞれぞれについて解説が行われました。</p>

<ul>
<li>プラットフォーム・・・パブリッククラウドか、プライベートクラウドか</li>
<li>構成管理(自動化)・・・Opscode Chefを使う</li>
<li>マネジメント(マルチクラウド)・・・<a href="http://www.enstratius.com">Enstratius</a>を使う</li>
</ul>


<p>パブリッククラウドかプライベートクラウドかについては、今回のセミナーはDellのクラウド関係ということで、プライベートクラウドに焦点が当たっていましたが、サービスやチームの性質や規模によってケースバイケースなので、決まった答えはないのかなと思いました。</p>

<p>構成管理ツールについては、私はChef一択ということはないと思っています。Chefは非常に多機能でマルチプラットフォーム対応が柔軟なぶん、やや複雑化しすぎてしまっていると思います。かといってPuppetの勢いはそれほど無いし、またはAnsibleやSaltやCuisineなのかというとそうでも無い気がしています。
言語やDSLがどうというより、「RedHat系Linuxに特化」などある程度OSを絞った形でやらないとchefでいうcookbookのメンテが無理すぎる、というのがchefを1年ほどさわって抱いた感想です。</p>

<h2>サイバーエージェントにおけるプライベートクラウド本格導入～その実情(サイバーエージェント：奈良さん)</h2>

<p>サイバーエージェント本体のインフラ部門が構築中のプライベートクラウドの内部の解説でした。実際の管理画面やネットワーク図などを含んだ詳細な解説がありました。</p>

<p>とにかく開発スピードの高速化に貢献できるプライベートクラウドを目指すという目的のもと、機能的なメリットよりはシンプルさを追求したものになっています。ディスク以外は冗長化をなるべくせず、アプリケーション側でフェイルオーバーを前提とした作りにするというくだりが印象的でした。</p>

<p>私はこれまで海外事業をやってきたのでこのプライベートクラウドを使う機会は無かったのですが、一応アカウントがあって管理画面入ってみたり仮想サーバーを作ってみたことはあります。</p>

<p>中途半端に中を知っているだけにコメントしづらいのですが、全社的にインフラを共有して効率化とコスト削減を狙うという基本姿勢は大賛成だしその方向でうまくいっていると思います。</p>

<p>AWSと比較されることが多いそうですが、多機能、複雑なAWSに対してとことんシンプルさを追求するサイバーエージェントのプライベートクラウドは、うまく棲み分けできると思います。</p>

<p>ただ独自路線を突き進むよりは、コミュニティ、たとえばOpenStackに追従したほうがいいと思います(ぼそっ</p>

<h2>Juju &ndash; Ubuntuのクラウドのオーケストレーションツール</h2>

<p>セミナーのセッションとは直接関係がないのですが、終わった後の懇親会で、Ubuntuの支援企業であるCanonicalの人が面白いツールを教えてくれました。</p>

<p>Juju<br/>
<a href="https://juju.ubuntu.com/">https://juju.ubuntu.com/</a></p>

<p>オーケストレーションツール(Orchestration Tool)といわれるツールです。</p>

<p>私はUbuntuは使っていないのですが、chefのcookbookがUbuntuベースで作られていることが多いので、Ubuntuを使えば簡単なのにと思うことはたまにあります。その話を振ってみたところ、Jujuの話がでてきました。オーケストレーションツールはchefのような構成管理ツールと同等には重要な存在になると思うのですが、まだ定番といえるものが出てきていません。今後ぜひ調べてみたいと思います。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第6回テックヒルズ「Let's Study Jenkins」- Jenkinsとのさまざまな付き合い方]]></title>
    <link href="http://chokkoyamada.github.io/blog/2013/06/18/techhills6th-jenkins/"/>
    <updated>2013-06-18T20:24:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2013/06/18/techhills6th-jenkins</id>
    <content type="html"><![CDATA[<p>2013/06/18 19:00~22:00に六本木ヒルズ(アカデミーヒルズ)で「第6回テックヒルズ Let&rsquo;s Study Jenkins ~さまざまなケーススタディ~」というイベントが行われたので行ってきました。</p>

<p>第6回テックヒルズ本日開催！【Ustream配信決定】<br/>
Let’s study Jenkins ～さまざまなケーススタディ～ : ATND<br/>
<a href="http://atnd.org/events/39910">http://atnd.org/events/39910</a></p>

<p>参加者700人超という平日の技術勉強会としてはかなりの規模で、この形式でやるのは6回目らしいのですが私は今回が初参加でした。</p>

<p>セッションは2つの部屋に分かれて行われました。私が参加したセッションについて紹介します。</p>

<h2>検索技術基盤開発のための結合テスト環境の自動化(楽天：萩原さん)</h2>

<p>検索基盤の開発にJenkinsを活用して、結合テストを自動化している話。単体テスト・結合テストの前にSmoke Testというフェーズがあり、早期発見可能なバグを検知する仕組みがあるというのが特徴的でした。Smoke Testの中身についてもう少し詳しく聞きたかった。。</p>

<p>結合テストについては15時間のビルドを分割して全て1時間以内に終わるようにして50台のテストサーバーで自動テストを回しているとのこと。それなりに大規模にJenkinsを活用している事例といえますが、ここまで緻密に自動テスト環境を構築するのは楽天内の検索システムのような大規模開発ならではという印象を持ちました。</p>

<h2>CROOZにおけるJenkins活用事例(CROOZ: 鈴木さん)</h2>

<p>コーディング規約に反したコードや除外ファイル(本番にデプロイしたくないファイル)の更新漏れを検知するのに活用しているののこと。自動テストに使うというより、その前段階で開発者へのフィードバックループを作るために活用しているという感じのようです。</p>

<p>そもそもソーシャルゲーム開発におけるテスト事情って最近どうなんでしょうか？　私が2年前にソーシャルゲーム開発をしているころは単体・結合テストを書いているという会社はあまり見かけなかったです。最近だと独自フレームワークが完成の域に達している会社も多いでしょうし、テストをするのは珍しくなくなっているのかもしれません。</p>

<h2>ぼくとJenkinsおじさんとの300日戦争(mixi: 五嶋さん)</h2>

<p>テスト数25万件、実行に45分かかっていたという、膨大なテストを高速化（時間短縮）するための奮闘の記録。</p>

<p>「モジュール読み込み時間を削る」「WriteするまでFixtureで生成したDBをキャッシュして使いまわす」という方法が最初に紹介されましたが、十分な効果が得られず苦労していたという話の後で、結局、最近Jenkinsスレーブ48台が使えるようになって8分でテスト終わるようになりました！という富豪的解決策で対応というオチになって、苦笑してしまいました。確かにリソースは大事ですね。</p>

<h2>アメーバピグとJenkinsと私 (サイバーエージェント: 丸山さん)</h2>

<p>2011年当時のアメーバピグはテストがまともになく、ci環境がないのでとりあえずJenkins導入してみたところ、数千個のFindbugs警告、160個は深刻、でパンドラの箱を開けてしまった＼(^o^)／というところから話が始まりました。そういう状況から2年間かけて徐々にci環境の整備を行なってきたとのこと。</p>

<p>後半では、Jenkinsを使ってバッチ処理をしているというのを興味深く聞きました。cronやSpringBatchではジョブの成否や実行時間の把握が複雑になりがちで、私もバッチ管理の有効な方法を探している途中だったからです。SpringBatchを捨てて自作のシンプルなフレームワークへの置き換え＋Jenkinsでのバッチ管理というのは一つの手法として合理的だと納得しました。</p>

<p>あと今回初めて知りましたが、アメーバピグは本番環境が2系統あって一週間ごとに切り替えて運用しているとのことです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2013(1) Redshiftのパフォーマンスと使いどころ]]></title>
    <link href="http://chokkoyamada.github.io/blog/2013/06/06/aws-summit-2013/"/>
    <updated>2013-06-06T13:25:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2013/06/06/aws-summit-2013</id>
    <content type="html"><![CDATA[<p>AWS Summit Tokyo 2013の中から2セッション、まとめておきたいと思います。1つめはRedshiftに関するセッションです。</p>

<p>セッション紹介 ｜ AWS Summit Tokyo 2013  <br/>
<a href="http://www.awssummittokyo.com/session.html#Tech-05">「Amazon Redshiftが切り開くクラウド・データウェアハウス」</a></p>

<p>私の勤務する<a href="http://aws.amazon.com/jp/about-aws/whats-new/2013/6/5/Amazon-Redshift-and-High-Storage-Instance-in-Tokyo-Region/">AMoAdでは、RedShiftがUS-Eastリージョンで使えるようになって以来注目していて、実際に本番環境で使ってきました。</a> 私は中心的にRedshiftをじっくり使ってきたわけではないのですが、運用担当として興味深く聴講しました。</p>

<h2>Redshiftの概要</h2>

<pre><code>エンタープライズシステムにおける活用ノウハウ

Amazon Redshiftの取り組みについて

クラウド型データウェアハウス
オンプレ環境におけるデータウェアハウスの課題
・初期投資
・運用管理
・成長予測・費用対効果

install backupなどのルーチンワークをAWSに任せて、codingとperformance tuningに割く時間を増やせる

RDS, DynamoDBなどのオンライントランザクション→ EMR, S3→Redshift

カラムナ型データベース
列が多いケースにはパフォーマンスの向上が見られやすい

* Leader Node クエリのパース・分析をしてC++コードを生成してcompute nodeに投げる

* compute nodes ここを増やすことで器を大きくできる

    1.6PBまで拡張可能

JDBCのPostgreSQLドライバを使える

AmazonS3かDynamoDBからの並列ロード

S3への自動バックアップ・増分バックアップ・オンデマンドのバックアップ　
リサイズする場合：新しいクラスタをバックグラウンドでプロビジョニング
ノード数×時間単価の課金　

日本ではデータウェアハウスとOLTPの中間的な使い方をしている場合が多い　
</code></pre>

<p>まずはRedshiftの概要の説明です。Redshiftはすでに基本的なところは調べて実際に使ってきたのでほとんどが既知の事項でした。</p>

<p>エンタープライズ向けを主に意識しているセッションだけあって聞き慣れない単語がいくつかありましたが・・・そもそもRedshiftは個人で気軽に試すには若干値が張る（最小構成でも1ノードを1ヶ月フルで使うと$0.85 x 24hour x 30dayで6万円程度）</p>

<pre><code>## Redshiftの性能は？

他と比較するとSEの寿命が縮まるので・・・

### 巨大テーブルからの検索処理

1.5TBくらいのデータの検索結果  500億件
8XL 2node 43.5sec
8XL 4node 27.8sec
8XL 8node 19.8sec

線形に性能が向上しているのに驚いた

### データロードのスピード 500億件

8XL 2node 2:54sec
8XL 4node 1:37
8XL 8node 0:46

### 1.2億件の検索結果

8XL 2node 3.30 sec
8XL 4node 1.40 sec
8XL 8node 1.80 sec

## バッチ処理は？

EMRとの比較
1.5TB, 500億件

EMR 29min
Redshift 17min

EMR 71min
Redshift 5min

チューニングのポイント
キー(index)

distribution keyに応じてスライスに配置される
sort keyをもとにレコードがソートされる

### チューニング効果
* 1.2億件

指定無しは1.8秒
指定ありは1秒

* バッチ処理

指定あり：24min
指定無し：16min

sort keyを入れるとロードは遅くなるので注意

### コスト:w
128coe 960gb 128tb storage
構築費はほぼ不要、維持管理のSEも不要、センター費用は不要

### 注意点は？
不得意なデータ形式もある
EMRで前処理

簡単につくれてしまうため、統制のきいていないシステムの乱立に注意

### まとめ

* 性能は線形にスケール
* バッチ処理も得意
* チューニングは新しい概念で
* 利用料課金はメリット大
* 注意点もある
</code></pre>

<p>次は野村総研の方からの検証結果報告です。データのSELECTが早いのは確かだと思います。ただ、セッションでも言及されているように、「不得意なデータ形式もある」ということで、結局のところRedshiftのポテンシャルをフルに引き出して使いこなすには、時間とともに溜まるノウハウの蓄積が欠かせない気がします。</p>

<p>データのロードについても同様で、<a href="http://www.hapyrus.com/products/flydata-for-redshift">FlyData for Amazon Redshift</a>というサービスがあるくらい、Redshiftに適切な速度で要領よくデータをアップロードするのは難しいという印象です。このへんも各所で検証が進むにつれて、うまいやり方というのが見いだされてくるのかなと思います。</p>
]]></content>
  </entry>
  
</feed>
