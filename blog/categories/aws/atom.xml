<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: aws | Continuous Ops]]></title>
  <link href="http://chokkoyamada.github.io/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://chokkoyamada.github.io/"/>
  <updated>2014-07-18T14:12:25+09:00</updated>
  <id>http://chokkoyamada.github.io/</id>
  <author>
    <name><![CDATA[Naoyuki Yamada]]></name>
    <email><![CDATA[yamada_naoyuki@cyberagent.co.jp]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS + Windows(C#)で構築する.NET最先端技術によるハイパフォーマンスウェブアプリケーション開発実践]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-grani-windows/"/>
    <updated>2014-07-18T13:19:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-grani-windows</id>
    <content type="html"><![CDATA[<p>ソーシャルゲームデベロッパーのGraniの河合さんによるC#のウェブアプリケーションの解説です。</p>

<p>私はWindowsでアプリケーションを書いたことも運用したこともないのですが、かなり昔にMS-DOSでシステム管理は少しやったことがあるので、Microsoftの技術には愛着を持っています。</p>

<p>一番驚いたのは、C#の機能をを活かして処理をほぼ非同期で行っているというところでした。
PHPなどでは絶対無理な処理なので、これはすごいなと。
私のプロダクトでやるならScalaになるのでしょうが、ここまでの境地に達するのはよほど言語に精通していないといけない気がします。</p>

<p>ソーシャルゲームのレスポンスで全て100msecを切るように返すことの大変さは分かっているつもりなので、レベルの違いを感じました。
Redisのパイプライン処理いいですね。</p>

<p>とにかくクールだなと思いました。ひたすら感心。</p>

<p>門外漢のC#やWindowsの話をあえて聞いてみてよかったです。</p>

<ul>
<li>AWS + C#によるウェブソーシャルゲーム</li>
<li>C# 50%, AWS 20%, その他 30%ぐらいの話</li>
<li>AWSだからといってC#を使うのに特別なことはない</li>
</ul>


<h2>using CSharp;</h2>

<ul>
<li>C#の開発にとことんこだわっている</li>
<li>もとはPHPだったが開発効率に不満を感じた</li>
<li>半年後にC#に全面移行</li>
<li><p>AWSを使っていたのでそのまま移行した</p></li>
<li><p>クライアントサイドからサーバーサイドまで全てをC#で！</p></li>
</ul>


<p>AWS + C#は全く問題ない。</p>

<ul>
<li>100 server</li>
<li>10000 req/sec</li>
<li>1000000000pv/day</li>
</ul>


<p>IIS8 + RDS + Redis(r3.2xlarge)20台</p>

<h2>なぜRDBMSを選択するのか</h2>

<ul>
<li>NoSQLでいい？けれど複雑化をおさえたい</li>
<li>RDBMSは単純なクエリなら1msec以下で返すがDynamoDBは・・・</li>
<li>周辺ツールが充実</li>
<li>スケールアップや分割で対応できるなら、スケールアウトに固執することもない</li>
</ul>


<h3>何よりRDSが良い</h3>

<p>手放し管理、Restore To Point in Timeには救われた</p>

<ul>
<li>SQL Server vs MySQL

<ul>
<li>C#としてはSQL Serverのほうが相性はいい</li>
<li>しかしRDSとしてみるとSQL Serverは貧弱</li>
<li>今はあるがMulti-AZも無かったし、ProvisionedIOPSの限界値も低かった</li>
<li>結果、MySQLを使っている</li>
</ul>
</li>
</ul>


<p>r3.8xlargeが最強</p>

<p>垂直分割 vs 水平分割</p>

<p>機能単位の垂直分割を採用</p>

<p>水平分割は避ける: 記述可能なクエリに大きな制限がかかってしまう アドホックなクエリでの集計が不可能になる
ほとんどのアプリケーションは、水平分割をする必要はないのでは？</p>

<p>DB管理はGUIで
HeidiSQLがおすすめ　phpMyAdminやCUIは積極的にdisりたい</p>

<p>アプリケーションからはMasterのみ参照
いまどきのRDSは十分パワフルなので、Slaveに分散するのは無用な複雑さを生むだけ
レプリケーション遅延は起きるので。</p>

<p>同一AZに配置する
AZを越えると普段0.5msec程度のクエリが2msec程度になる</p>

<p>C#的な活用としては、コネクションを型で分けるとコンパイルでチェックできる
生のSQLを書いている</p>

<p>テーブル定義から自動生成
テーブルと1:1でひもづいたクラスがある
T4テンプレート + ADO.net</p>

<p>半自動生成くらいの位置づけ</p>

<ul>
<li><p>全階層でのキャッシュの徹底</p>

<ul>
<li>データベース</li>
<li>Memcache-Redis</li>
<li>Static変数: アイテム名など不変の情報はキャッシュ　</li>
<li>リクエスト単位</li>
</ul>
</li>
</ul>


<p>アプリケーションコードによるJOIN</p>

<p>LINQ to Objectsで簡単。SQLよりもずっと楽</p>

<h2>Redis</h2>

<p>RDSの不得意な部分を補える
高パフォーマンスなのでMemcached代わりのキャッシュ用途に
用途ごとのグループ分けと単純分散</p>

<p>Master Slave構成をとっている
dump出力時にCPUをくうので</p>

<p>ElastiCache Redisは試したときにパフォーマンスがでなかったので使っていない</p>

<p>Protocol Buffersを使っている
高速・省サイズなので</p>

<h2>Performance + Async</h2>

<p>100msecを切るように作っている
C# 5.0を活用</p>

<p>言語構文レベルでサポートされる非同期
同期と同じように非同期が書ける Graniではコード全体が非同期で書かれている</p>

<p>Redisならパイプライン化可能
全てが非同期で自動でパイプライン化される</p>

<p>性能と設計を両立できる</p>

<h2>Log for performance</h2>

<p>外部通信を全て記録する
アプリケーション側で送信前後をフックして記録
後述するGlimpseやSumo Logicで解析する
アプリ側でやると負荷がない</p>

<h3>Glimpse &ndash; 可視化</h3>

<p>全体の実行時間のほか、あらゆるメトリックスを常時可視化
<a href="http://getglimpse.com">http://getglimpse.com</a></p>

<p>Explainの常時表示　手動でExplainはやらない
Redis送受信の表示</p>

<h3>日常的開発</h3>

<p>Git + GitHub
Jenkins
DeployはValentia(自社ツール)</p>

<p>Sumo Logicでログ解析
New Relicでモニタリング</p>

<p>Semantic Logging + Redshift + Tableau
<a href="http://slab.codeplex.com">http://slab.codeplex.com</a></p>

<h2>まとめ</h2>

<ul>
<li>C# + AWSは現実界</li>
<li>構成は堅く、シンプルに</li>
<li>環境は常に最新に</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: Amazon CloudFrontを利用したサイト高速化およびセキュア配信]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-cloudfront/"/>
    <updated>2014-07-18T12:21:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-cloudfront</id>
    <content type="html"><![CDATA[<p>ソリューションアーキテクトの北迫さんによる、Cloudfrontの活用方法についてです。</p>

<p>普段RTBをやっているので、相手はユーザーのブラウザではなくてSSPやアドネットワークのAPIで、普段CDNを意識することはあまりありません。
バナー広告の画像やJavaScriptを置いているくらいです。
将来、動画配信とかするなら詳しくなっておきたいなと・・・</p>

<p>ただ現時点でも、劇的にコストや負荷を軽減する方法として、CDNとしてのCloudfrontにはまだ利用シーンがあるのではと思って考えています。</p>

<h2>サイト高速化</h2>

<p>DNSの仕組みを使って最適なエッジへ誘導
52 Edge locations</p>

<p>80:20の法則
ページ本体のレスポンスタイムは20%に過ぎず、それ以外の部分に80%の時間を使っている</p>

<p>ispとispの間のixのところから足が生える形でAWS edgeがある</p>

<h3>CDN Edge Locationの活用</h3>

<p>分散型CDNと集中型のCDN</p>

<p>分散型CDN: ユーザーに近いISPのところにEdgeがある キャッシュヒット率が低い傾向
集中型CDN: キャッシュ共有 Cloudfrontはこちら</p>

<p>CloudfrontのEdgeに可能な限りキャッシュさせることが重要</p>

<ul>
<li><p>静的コンテンツ 805
キャッシュTTLも可能な限り長く、クライアント側にもキャッシュさせる</p></li>
<li><p>動的コンテンツ 20%</p>

<ul>
<li>ページ共通のもの</li>
<li>パーソナライズされたもの

<ul>
<li>動的に生成されるが、ページ自体は一定期間共通 QueryStringを活用しているもの</li>
<li>HTTPヘッダによるページ切り替えしているもの</li>
<li>cache-conrtol headerとminimum ttlで調整</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>キャッシュしすぎるとEdgeを通すオーバーヘッドはないか？
last-modified/ETag ヘッダ
if-modified-since 更新なしなら304を返す</p>

<ul>
<li><p>ヒット率向上のための要素</p>

<ul>
<li>キャッシュ時間</li>
<li>URLの共通化</li>
<li>Etag/Last-modifiedヘッダの活用</li>
<li>Query Stringsパラメータの固定化</li>
<li>転送対象Header値の固定化</li>
</ul>
</li>
<li><p>Cloudfrontは完全一致でキャッシュを共有</p></li>
<li><p>キャッシュヒット状況はレスポンスヘッダで</p>

<ul>
<li>X-Cacheの値を見る</li>
<li>X-Amz-Cf-IdにIDが入る</li>
</ul>
</li>
</ul>


<p>キャッシュができない動的ページはプロキシとして利用</p>

<p>Dynamic Contens Acceleration</p>

<ul>
<li>Post/Put/Header/Cookie対応</li>
</ul>


<p>CloudfrontのEdgeを経由させても多くの動的ページが扱えるようになった</p>

<ul>
<li>Keep-Alive Connection:  3 way handshakeのカット</li>
</ul>


<p>CDN &ndash; Originの間でKeepAliveする
HTTPS通信ならSSL Terminationでより効果が大きい</p>

<ul>
<li>TCPスロースタート</li>
</ul>


<p>ネットワークの輻輳を回避するために少しつづパケットを増やしながら量を増やしていく仕組み</p>

<ul>
<li>DNS Lookupの高速化</li>
</ul>


<p>Route53を活用するとLookupが早くなる: Cloudfrontと同じロケーションにサーバーがある &ndash;> 近い
CloudfrontはAlternative Domain Name: レコードセットのTypeをCNAMEではなくAレコードのエイリアスを利用することでクエリ回数の削減が可能</p>

<p>Cloudfront behaviorの活用
正規表現でURL毎に異なるキャッシュポリシーを適用できる
オリジンサーバーのほうで設定をする必要がない　</p>

<h2>セキュア配信</h2>

<ul>
<li><p>Httpsサポート</p></li>
<li><p>GEO Restriction</p></li>
<li><p>Signed URL(署名付きURL)</p>

<ul>
<li>Cloudfront経由で配信するコンテンツに対して期間指定URLを生成することで、配信コンテンツを保護する機能</li>
<li>ポリシーを指定する</li>
<li>Origin Access Identity(OAI)を使うと特定のCloudfrontからしかアクセスできないようにできる。一般のサーバーから制限する場合はIPアドレスで(CloudfrontのIPは公開されている)</li>
<li>プレミアムコンテンツ配信, Streaming配信などに利用</li>
<li>有効時間の設定は、ダウンロードならサイズにかかわらず短時間でOK　ストリーミングは映像・音声の再生時間+αを設定</li>
<li>Behavior毎の設定、正規表現を利用してDistributionを分けなくても特定のコンテンツのみ保護可能</li>
<li>Cache-controlヘッダも同様に利用できる</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<ul>
<li>インフラアプローチでの高速化施策</li>
<li>動的コンテンツにもうまく活用できる</li>
<li>セキュアなコンテンツ配信も容易かつ高速化が可能</li>
</ul>


<p>2014/9/9 AWS Cloud Strage &amp; DB Day
<a href="http://csd.awseventsjapan.com">http://csd.awseventsjapan.com</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: Amazon Redshiftによるリアルタイム分析サービスの構築]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad/"/>
    <updated>2014-07-17T13:08:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad</id>
    <content type="html"><![CDATA[<p>Cookpadのエンジニアの青木さんによる、Redshiftの活用方法です。　</p>

<p>さきほどのEMRのセッションも聞きつつも、SQLの世界は深いので、まだまだSQLで頑張れる部分はたくさんあるのではないかと思っています。
Redshiftで可能なことのごく一部しか使っておらず、「Redshiftじゃきつい」というレベルにもまだないです。</p>

<p>ただ、いうほど”リアルタイム”ではなかったです。ユーザーからの検索はリアルタイムで直接SELECTしているみたいですが、データ更新はバッチ処理でした。</p>

<p>User &ndash; EC2 &ndash; Redshiftという構成になっているのが一番驚きました。「たべみる」がB2Bサービスなのでそれほど同時に使う人数が多くないのでしょうが、こういう構成は無理かなと思い込んでいたのでとても参考になりました。</p>

<h2>たべみる: 検索システム</h2>

<ul>
<li>単語の検索頻度</li>
<li>単語の組み合わせ頻度</li>
<li>現在盛り上がっている単語</li>
<li>ユーザーの年代や居住地域を軸とした分析</li>
</ul>


<p>「バレンタイン」のキーワード分析　単語の組み合わせ　マッチ度　バレンタイン + 本命, 簡単, 大量</p>

<h2>たべみるのシステム構成</h2>

<p>User &ndash; ELB &ndash; EC2 &ndash; Redshift</p>

<p>Rails4 / Ruby2.1
dw2.large x 12</p>

<p>目標応答時間 500msec</p>

<p>応答速度向上の施策
圧縮タイプの選択
sort key: where句で入れているものは全てSort Keyに入れる 大きく削るならDist Key, 細かいチューニングはSort key
サマリーテーブル: 大きいデータをクエリすると絶対に時間かかるので、サマっておく</p>

<p>サマリーテーブルいつ作る？
安心と伝統の夜間バッチ 37minで実行できているのでHourlyの更新も可能だが、あえてやっていない。不要なので。
B2Bサービスなので、1日に少しずつ追加されてもあまり意味が無いため。</p>

<p>ログまたはMySQL &ndash;> file &ndash;> Redhisft(raw &ndash;> 中間データ &ndash;> summaryの三段階)</p>

<h2>データ連携の詳細</h2>

<p>信頼と実績のTSV渡し</p>

<p>他の用途ではfluentdによる継続ロードも</p>

<h2>SQLによるデータ処理</h2>

<ul>
<li><p>ELTのお約束</p>

<ul>
<li>エクスポート禁止:　データ移動は遅い　 DB外処理は非並列</li>
<li>UPDATE禁止:  複数回実行しにくい(冪等にしておきたい) VACUUMが厄介</li>
<li>1行INSERT禁止:  COPYかINSERT SELECT</li>
</ul>
</li>
<li><p>INSERT SELECTだけ使え！！</p></li>
<li><p>SQLでは書けなかった処理</p>

<ul>
<li>日本語処理　半角→全角変換</li>
<li>可変数カラム　タブ区切り文字列の分割</li>
<li>要するに文字列処理がきつい</li>
</ul>
</li>
<li><p>SQLで書ける！ こんな処理</p>

<ul>
<li>単語の組み合わせ生成  ジョイン</li>
<li>未来の月曜日N週ぶんの生成 ジョイン</li>
<li>テーブルの縦横変換 ジョイン</li>
<li>移動平均、移動累積和 ウィンドウ関数</li>
<li>グループごとのランキングTOPN ウィンドウ関数</li>
</ul>
</li>
<li><p>テーブルの縦横変換の例</p></li>
<li>グループごとのランキングの例 ウィンドウ関数を使うと、分割するけど、これを集約せずに結果だけ取ることができる

<ul>
<li>rank() over ( partition by ~ order by ~)</li>
</ul>
</li>
</ul>


<h2>データ更新のパターン</h2>

<ul>
<li><p>差分更新</p>

<ul>
<li>追加されたデータだけ更新する</li>
<li>デメリットは、冪等にしくくいこと</li>
<li>そのため、あらかじめ生成されるレンジのデータを消してからデータを挿入する処理にする</li>
</ul>
</li>
<li><p>洗い替え</p>

<ul>
<li>dropまたはtruncateして作りなおす</li>
<li>差分を考える必要がない</li>
<li>遅い</li>
<li>新しいテーブルを作ると権限(GRANT)を1個1個つけて回る必要があり、面倒</li>
<li>VACUUM問題</li>
</ul>
</li>
<li><p>アトミック洗い替え</p>

<ul>
<li>新しいテーブルを作ってる途中にテーブルが無くなってしまうので、テーブルが作り終わってからTRANSACTION内でALTER TABLE RENAMEする</li>
<li>24時間参照するテーブルではこれを使う</li>
<li>デメリットとしては、データが2倍になってしまう</li>
</ul>
</li>
<li><p>応用：アトミックな本番切り替え</p>

<ul>
<li>複数のテーブルをいっぺんに切り替える</li>
<li>複数のテーブルがお互いにデータが関連している場合</li>
</ul>
</li>
<li><p>更新パターンの使い分け</p>

<ul>
<li>生データは差分更新</li>
<li>中間データは洗い替え</li>
<li>サマリーデータはアトミック洗い替え</li>
</ul>
</li>
</ul>


<h2>なぜRedshiftにしたのか</h2>

<ul>
<li>COOKPADがAWSにあるから</li>
<li>マネージドサービスだから</li>
<li>並列処理能力が高いから</li>
<li>ウィンドウ関数など高度な機能が実装されているから</li>
<li>ある程度オンライン処理にも耐えられるから</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: AWSビッグデータサービス Deep Dive]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014/"/>
    <updated>2014-07-17T12:20:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014</id>
    <content type="html"><![CDATA[<p>AWSソリューションアーキテクトのJiang yifengさんによるEMRを中心とした技術の詳説です。</p>

<p>私はまだEMRをヘビーに使ったことはなくて、AWSサービスの中でいうとRedshiftのほうをよく使っています。
ただ、EMRのポテンシャルはとても高く、いま最も使っていきたいサービスの一つです。
他のクラウドサービスに似たサービスが無いことも特徴かと思います。</p>

<p>私が最近EMRに注目しているのは、ずっと起動し続けるサービスではデータが収まりきらなくなってきた、という課題があります。
私が取り組んでいるプロダクトでは、一日に約2TBのログが生まれています。圧縮しても数百GB。そうすると、RDSやRedshift, ElasticSearchなどの起動しっぱなしのクラスタにデータを格納し続けるのが困難になってきました。運用もきついですし、コスト的にもきついです。</p>

<p>そこで、古いデータを消していくという運用になるのですが、後から古いデータにアクセスしたいケースはやはりあります。
また、RedshiftでSQL、というだけではこなせないタスクも想定する必要が出てきたため、EMRを検討しています。</p>

<h3>デザインパターン</h3>

<ul>
<li>一時的なクラスタの活用</li>
<li>ジョブ実行中のみクラスタが存在</li>
<li><p>データはS3に永続化される</p></li>
<li><p>タスクノードの活用</p>

<ul>
<li>Spotインスタンスを使ってコスト削減</li>
<li>短時間で大量のリソースを必要とする場合、S3から大量のデータをHDFSのコピーする際に一時的にタスクノードを追加して、HS1インスタンスなどにデータをロードする手法</li>
</ul>
</li>
</ul>


<h2>ベストプラクティス</h2>

<ul>
<li><p>常に現世代のインスタンスタイプを使用</p></li>
<li><p>ワークロードに最適なノードタイプを選ぶ</p>

<ul>
<li>HS1 HDFS用途</li>
<li>I2 and HS1 ディスクIOが多いジョブ</li>
<li>大きめのノードで構成する小さなクラスタが効率的</li>
</ul>
</li>
<li><p>最適なファイルサイズ</p>

<ul>
<li>小さいファイル(100MB以下)を下げる</li>
<li>S3でHadoop利用の場合は1~2GBが最適なファイルサイズ

<ul>
<li>1mapperからS3のデータ取得速度 10~15mb/s</li>
<li>Mapper処理は60秒以上であるべき 60sec * 15mb = 1GB</li>
</ul>
</li>
<li>S3DistCpを使ってファイルを結合して最適なサイズに。</li>
</ul>
</li>
</ul>


<h2>チューニング</h2>

<ul>
<li><p>最強のチューニングはデータを効率よく保持すること</p></li>
<li><p>Hadoopはバッチ向け</p></li>
<li><p>Hadoop処理時間の目安は1時間〜数日</p></li>
<li><p>短いジョブは他の技術がフィットするかも</p>

<ul>
<li>Apache Storm</li>
<li>Apache Spark</li>
<li>Redshift</li>
</ul>
</li>
<li><p>チューニングについて</p></li>
<li><p>ノード追加！！</p></li>
<li><p>ビジネスの価値を最大化する目的からすると一番早い</p></li>
<li><p>Gangliaでクラスタをモニタリング</p></li>
<li><p>EMRなら1クリックインストール</p></li>
<li><p>例：ネットワークI/O</p>

<ul>
<li>もっとも重要なメトリック。特にS3を使う場合</li>
<li>1つのインスタンスからなるべく多くのネットワークI/Oを引き出す: Mapper数追加</li>
<li>Gangliaでネットワークスループットをチェック例えば200mbpsしか使っていなかったらMapperを追加することで改善する可能性が高い</li>
</ul>
</li>
</ul>


<h2>プラットフォームとしてのEMR</h2>

<h3>HBase</h3>

<ul>
<li><p> 書き込みが激しいものに有効</p></li>
<li><p>OpenTSDB</p>

<ul>
<li>HBase上のtime series database</li>
<li>大規模なモニタリング用</li>
<li>秒間数百万のデータ書き込み</li>
</ul>
</li>
<li><p>自動／手動でAmazon S3にHBaseをバックアップ</p>

<ul>
<li>フルバックアップ／増分バックアップ/指定のバージョンに簡単リストア</li>
</ul>
</li>
</ul>


<h3>Impala</h3>

<ul>
<li>SQL on Hadoop</li>
<li><p>Hiveと互換性が高い: 一部のユースケースにおいてはHiveを置き換えられる</p></li>
<li><p>ストレージレイヤー　永続クラスタのHDFSまたはHbaseを使う必要がある。現時点ではS3に未対応</p></li>
</ul>


<h3>Presto</h3>

<ul>
<li>ブートストラップでインストール</li>
<li>Impalaと違い、S3のデータにダイレクトにアクセス可能なところ</li>
</ul>


<h3>Spark</h3>

<ul>
<li>非常に光速</li>
<li>インメモリで処理しきれるならMapReduceより早いケースが多い</li>
<li>ブートストラップでインストール</li>
<li>ver0.8をサポート。1.0はcoming soon</li>
<li>Sparkはメモリを大量に使う。R3系やSpotインスタンスを利用</li>
<li>CloudWatchでSparkのメトリックスをサポートする JVMの監視が可能</li>
<li>Spark Streaming + Amazon Kinesisの構成でリアルタイムで分散処理</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2013(1) Redshiftのパフォーマンスと使いどころ]]></title>
    <link href="http://chokkoyamada.github.io/blog/2013/06/06/aws-summit-2013/"/>
    <updated>2013-06-06T13:25:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2013/06/06/aws-summit-2013</id>
    <content type="html"><![CDATA[<p>AWS Summit Tokyo 2013の中から2セッション、まとめておきたいと思います。1つめはRedshiftに関するセッションです。</p>

<p>セッション紹介 ｜ AWS Summit Tokyo 2013  <br/>
<a href="http://www.awssummittokyo.com/session.html#Tech-05">「Amazon Redshiftが切り開くクラウド・データウェアハウス」</a></p>

<p>私の勤務する<a href="http://aws.amazon.com/jp/about-aws/whats-new/2013/6/5/Amazon-Redshift-and-High-Storage-Instance-in-Tokyo-Region/">AMoAdでは、RedShiftがUS-Eastリージョンで使えるようになって以来注目していて、実際に本番環境で使ってきました。</a> 私は中心的にRedshiftをじっくり使ってきたわけではないのですが、運用担当として興味深く聴講しました。</p>

<h2>Redshiftの概要</h2>

<pre><code>エンタープライズシステムにおける活用ノウハウ

Amazon Redshiftの取り組みについて

クラウド型データウェアハウス
オンプレ環境におけるデータウェアハウスの課題
・初期投資
・運用管理
・成長予測・費用対効果

install backupなどのルーチンワークをAWSに任せて、codingとperformance tuningに割く時間を増やせる

RDS, DynamoDBなどのオンライントランザクション→ EMR, S3→Redshift

カラムナ型データベース
列が多いケースにはパフォーマンスの向上が見られやすい

* Leader Node クエリのパース・分析をしてC++コードを生成してcompute nodeに投げる

* compute nodes ここを増やすことで器を大きくできる

    1.6PBまで拡張可能

JDBCのPostgreSQLドライバを使える

AmazonS3かDynamoDBからの並列ロード

S3への自動バックアップ・増分バックアップ・オンデマンドのバックアップ　
リサイズする場合：新しいクラスタをバックグラウンドでプロビジョニング
ノード数×時間単価の課金　

日本ではデータウェアハウスとOLTPの中間的な使い方をしている場合が多い　
</code></pre>

<p>まずはRedshiftの概要の説明です。Redshiftはすでに基本的なところは調べて実際に使ってきたのでほとんどが既知の事項でした。</p>

<p>エンタープライズ向けを主に意識しているセッションだけあって聞き慣れない単語がいくつかありましたが・・・そもそもRedshiftは個人で気軽に試すには若干値が張る（最小構成でも1ノードを1ヶ月フルで使うと$0.85 x 24hour x 30dayで6万円程度）</p>

<pre><code>## Redshiftの性能は？

他と比較するとSEの寿命が縮まるので・・・

### 巨大テーブルからの検索処理

1.5TBくらいのデータの検索結果  500億件
8XL 2node 43.5sec
8XL 4node 27.8sec
8XL 8node 19.8sec

線形に性能が向上しているのに驚いた

### データロードのスピード 500億件

8XL 2node 2:54sec
8XL 4node 1:37
8XL 8node 0:46

### 1.2億件の検索結果

8XL 2node 3.30 sec
8XL 4node 1.40 sec
8XL 8node 1.80 sec

## バッチ処理は？

EMRとの比較
1.5TB, 500億件

EMR 29min
Redshift 17min

EMR 71min
Redshift 5min

チューニングのポイント
キー(index)

distribution keyに応じてスライスに配置される
sort keyをもとにレコードがソートされる

### チューニング効果
* 1.2億件

指定無しは1.8秒
指定ありは1秒

* バッチ処理

指定あり：24min
指定無し：16min

sort keyを入れるとロードは遅くなるので注意

### コスト:w
128coe 960gb 128tb storage
構築費はほぼ不要、維持管理のSEも不要、センター費用は不要

### 注意点は？
不得意なデータ形式もある
EMRで前処理

簡単につくれてしまうため、統制のきいていないシステムの乱立に注意

### まとめ

* 性能は線形にスケール
* バッチ処理も得意
* チューニングは新しい概念で
* 利用料課金はメリット大
* 注意点もある
</code></pre>

<p>次は野村総研の方からの検証結果報告です。データのSELECTが早いのは確かだと思います。ただ、セッションでも言及されているように、「不得意なデータ形式もある」ということで、結局のところRedshiftのポテンシャルをフルに引き出して使いこなすには、時間とともに溜まるノウハウの蓄積が欠かせない気がします。</p>

<p>データのロードについても同様で、<a href="http://www.hapyrus.com/products/flydata-for-redshift">FlyData for Amazon Redshift</a>というサービスがあるくらい、Redshiftに適切な速度で要領よくデータをアップロードするのは難しいという印象です。このへんも各所で検証が進むにつれて、うまいやり方というのが見いだされてくるのかなと思います。</p>
]]></content>
  </entry>
  
</feed>
