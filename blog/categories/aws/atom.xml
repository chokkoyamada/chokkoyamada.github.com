<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: aws | Continuous Ops]]></title>
  <link href="http://chokkoyamada.github.io/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://chokkoyamada.github.io/"/>
  <updated>2014-07-18T16:03:09+09:00</updated>
  <id>http://chokkoyamada.github.io/</id>
  <author>
    <name><![CDATA[Naoyuki Yamada]]></name>
    <email><![CDATA[yamada_naoyuki@cyberagent.co.jp]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: Amazon Kinesis Deep Dive]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-kinesis-deep-dive/"/>
    <updated>2014-07-18T15:10:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-kinesis-deep-dive</id>
    <content type="html"><![CDATA[<p>ソリューションアーキテクトの大谷さんと開発マネージャの堀さんによる、Kinesisの詳説です。
Kinesisの開発マネージャの方が解説してくれたこともあり、とても意義あるものでした。</p>

<h3>Kinesisの新規ローンチ</h3>

<ul>
<li>東京リージョンローンチ</li>
<li>Fluentdプラグイン <a href="https://github.com/awslabs/aws-fluent-plugin-kinesis">https://github.com/awslabs/aws-fluent-plugin-kinesis</a></li>
<li>MQTTアダプター <a href="https://github.com/awslabs/mqtt-kinesis-bridge">https://github.com/awslabs/mqtt-kinesis-bridge</a></li>
</ul>


<h2>事例紹介</h2>

<ul>
<li>ガリバー <a href="http://221616.com/gulliver/news/press/20140715-13667.html">http://221616.com/gulliver/news/press/20140715-13667.html</a></li>
<li>Pencil(リアルタイムユーザーモニター)</li>
<li>SmartInsight(Beaconとの距離をロギング)</li>
<li>Supercell</li>
<li>bizo</li>
</ul>


<h2>Kinesis詳細</h2>

<h3>なぜリアルタイム？</h3>

<ul>
<li>測定(Metering)サービス　使った分だけ課金されるという特性　オペレーションを測定しないといけない</li>
<li>毎秒数千万レコード</li>
<li>毎時数テラバイト</li>
<li>数十万のデータ・ソース</li>
<li><p>月末にはオーディターでの100%の正確性</p></li>
<li><p>毎時数百万のファイル</p></li>
<li>スケールの課題</li>
<li>リアルタイムの要望</li>
<li><p>高い運用コスト</p></li>
<li><p>要求の変化
毎時か毎日のデータ処理が従来の要求だったが、リアルタイム、早い意思決定、KeepEverything、エラスティックな拡張性、複数の目的に応じて同じデータを並行処理したい、などの新しい要求が出てきた。</p></li>
</ul>


<h3>Kinesis概要</h3>

<p>用途単位でStreamを作成し、Streamは１つ以上のShardで構成される
Shardは入力側秒間１MB 1000TPB 出力側2mB, ５TPSのキャパシティ
入力されたデータは複数のAZに２４時間保存
Shardの増減でスケール</p>

<h3>データ入力</h3>

<p>HTTPS/POSt
SDK
Fluentd
Flume
Log4J
etc</p>

<p>ProducerがPut Recordするサンプル AWS CLIでできる</p>

<p>Shardへの分配ロジック：　md5でハッシュ化して該当のShardに分配される
パーティションキーを何にするかは重要</p>

<p>パーティションキーの数 > shardの数
カーディナリティーの高いパーティションキーを使う</p>

<p>シーケンス番号を使って何度でも読むことができる
何度取得してもシーケンス番号の順番は変わらない:重要</p>

<p>データ取得と処理</p>

<p>API
Kinesis Client Library/ConnectorLibrary
Storm
EMR</p>

<h2>どうやって信頼性と拡張性のあるアプリケーションを作るの？</h2>

<ul>
<li>Kinesis Client Libraryを提供

<ul>
<li>Shardと同じ数のWorker</li>
<li>Workerを均等にロードバランシング</li>
<li>障害完治と新しいWorkerの立ち上げ</li>
<li>shardの数に応じてWorkerが動作する</li>
<li>Autoscaling</li>
<li>チェックポインティング、At least once処理</li>
</ul>
</li>
</ul>


<p>これらの煩雑な処理を意識することなく、ビジネスロジックに集中できる</p>

<h3>重複データについて</h3>

<p>ネットワーク障害や500レベルエラーはリトライをする
リカバリやロードバランシングでデータが最後のチェックポイントからリプレイされる</p>

<ul>
<li>ユースケースを理解する

<ul>
<li>冪等なアプリをつくる</li>
<li>重複を許容する</li>
</ul>
</li>
</ul>


<h3>Kinesis Connector Library</h3>

<p>S3, DynamoDB, Redshift
4つのインタフェースを使うと簡単に書ける</p>

<p>1つのデータをいろいろなシステムで
プロデューサーの負荷軽減
データの一貫性を保ちたい</p>

<p>Kinesisに全てのデータを１回入力する
必要に応じて新しいアプリを追加していく
Agilityを高める</p>

<h2>Elasticな拡張性</h2>

<ul>
<li>Streamは１つ以上のキャパシティで構成　Shardでキャパシティプランニング</li>
<li>SplitShard API Shardを半分に分割</li>
</ul>


<p>shardやEC2もキャパシティがある
ProvisionedThroughputExceededException</p>

<p>shard１つで14$/month
Getトランザクションは無料</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: Amazon Kinesisを用いたリアルタイムのゲーム分析システムと、AWS ElasticBeanstalk＆Amazon DynamoDB を活用したゲーム運営]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-dynamo-kinesis/"/>
    <updated>2014-07-18T14:15:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-dynamo-kinesis</id>
    <content type="html"><![CDATA[<p>Ripplationという会社の安藤さんと立本さんによるゲーム運営にAWSのマネージドサービスを活用する話です。
最近のゲーム界隈にうといのですが、「騎士とドラゴン」が代表的タイトルですかね。</p>

<p>とことん運用を楽にする側に振り切っているのは清々とします。</p>

<p>Kinesis &ndash; ElasticBeansTalk &ndash; S3の組み合わせ方がかなり独特で、二段階に処理を分けるというのはとてもおもしろいと思いました</p>

<ul>
<li>いかにして最小人数でサーバー側の開発を行うか</li>
<li><p>以下にしてサーバーコストを下げるか</p></li>
<li><p>スケール・耐障害の自動化</p></li>
<li>監視システムも簡単にしたい</li>
</ul>


<p>なので、ElasticBeansTalk + DynamoDBのみで構成することにした</p>

<h2>AWSを使ってみてわかったこと</h2>

<ul>
<li>すぐ始められる</li>
<li>アプリをサーバーにデプロイするまでに流れを作るのが簡単</li>
<li>1から整える必要がない</li>
<li>思った以上に実用に耐えられる</li>
<li>ほとんど放置が可能: 最近サーバーをコンソールで調整したくらい</li>
</ul>


<h3>ElasticBeansTalkの注意点</h3>

<ul>
<li>デプロイ時に一瞬アクセスできないことがある: 気にせずデプロイしている。エラー処理はアプリケーション側で行っている</li>
<li>オートスケーリングの調整はきっちりしておく</li>
</ul>


<h3>DynamoDBの注意点</h3>

<ul>
<li>社内にいるDB技術者の文句やいちゃもんに負けない　問題が出たら後付けで</li>
<li>バッチ処理をしっかり使う、リトライも行う</li>
<li>スループットの限界値は急激に変化させられない: 急激な書き込みは読み込みはできない</li>
<li>バックアップするかどうか　リストアする場合ってどんな状況だろうか</li>
</ul>


<h3>汎用化なんて考えたらダメ</h3>

<ul>
<li>AWSを使い倒さないと真の良さは発揮されない</li>
<li>そんなにどれでも動く仕組みって重要なんでしょうか。</li>
</ul>


<h2>ログデータの収集・集計</h2>

<ul>
<li>結局、最初はDynamoDBだけでなんとかした</li>
</ul>


<h2>KinesisとBigData</h2>

<h3>ビッグデータとはなにか</h3>

<p>単体ではよくわからないデータこそがビッグデータ</p>

<p>達成課題：毎秒10万件のデータを収集する</p>

<p>Linux
TCP
28000個ぐらいのポート
TIMEWAIT 60sec
実測値への縫製係数: 0.6
1server 282 req/sec</p>

<p>チューニング後：</p>

<p>Linux
TCP
64000 Port
TIMEWAIT 10sec
1server 4000req/sec</p>

<p>26台あれば　 3870x26=100620req/sec</p>

<p>ただ、これをどうやって集める？ 一般的なサーバーでつくろうとするとdisaster recovery含めて大変</p>

<p>Kinesisならシャードを100個立てれば終了</p>

<p>Grasslandというツールを開発中: データを分析して</p>

<h2>GrasslandでのKinesisの使いどころ</h2>

<p>1 クライアントからはKinesisにデータを直接投げる
2 ElasticBeansTalkはS3にキャシュを保存
3 S3はcacheの解析リクエストをKinesisに返す
4 Kinesis &ndash;> EBT に解析リクエストを投げる
5 S3 &ndash;> EBT はキャッシュを返す
6 EBT &ndash;> S3 解析結果を渡す</p>

<p>セキュリティを担保できる工夫はいろいろできる</p>

<p>Kinesisは世界のデータを集めるように作られている</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: AWS + Windows(C#)で構築する.NET最先端技術によるハイパフォーマンスウェブアプリケーション開発実践]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-grani-windows/"/>
    <updated>2014-07-18T13:19:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-grani-windows</id>
    <content type="html"><![CDATA[<p>ソーシャルゲームデベロッパーのGraniの河合さんによるC#のウェブアプリケーションの解説です。</p>

<p>私はWindowsでアプリケーションを書いたことも運用したこともないのですが、かなり昔にMS-DOSでシステム管理は少しやったことがあるので、Microsoftの技術には愛着を持っています。</p>

<p>一番驚いたのは、C#の機能をを活かして処理をほぼ非同期で行っているというところでした。
PHPなどでは絶対無理な処理なので、これはすごいなと。
私のプロダクトでやるならScalaになるのでしょうが、ここまでの境地に達するのはよほど言語に精通していないといけない気がします。</p>

<p>ソーシャルゲームのレスポンスで全て100msecを切るように返すことの大変さは分かっているつもりなので、レベルの違いを感じました。
Redisのパイプライン処理いいですね。</p>

<p>とにかくクールだなと思いました。ひたすら感心。</p>

<p>門外漢のC#やWindowsの話をあえて聞いてみてよかったです。</p>

<ul>
<li>AWS + C#によるウェブソーシャルゲーム</li>
<li>C# 50%, AWS 20%, その他 30%ぐらいの話</li>
<li>AWSだからといってC#を使うのに特別なことはない</li>
</ul>


<h2>using CSharp;</h2>

<ul>
<li>C#の開発にとことんこだわっている</li>
<li>もとはPHPだったが開発効率に不満を感じた</li>
<li>半年後にC#に全面移行</li>
<li><p>AWSを使っていたのでそのまま移行した</p></li>
<li><p>クライアントサイドからサーバーサイドまで全てをC#で！</p></li>
</ul>


<p>AWS + C#は全く問題ない。</p>

<ul>
<li>100 server</li>
<li>10000 req/sec</li>
<li>1000000000pv/day</li>
</ul>


<p>IIS8 + RDS + Redis(r3.2xlarge)20台</p>

<h2>なぜRDBMSを選択するのか</h2>

<ul>
<li>NoSQLでいい？けれど複雑化をおさえたい</li>
<li>RDBMSは単純なクエリなら1msec以下で返すがDynamoDBは・・・</li>
<li>周辺ツールが充実</li>
<li>スケールアップや分割で対応できるなら、スケールアウトに固執することもない</li>
</ul>


<h3>何よりRDSが良い</h3>

<p>手放し管理、Restore To Point in Timeには救われた</p>

<ul>
<li>SQL Server vs MySQL

<ul>
<li>C#としてはSQL Serverのほうが相性はいい</li>
<li>しかしRDSとしてみるとSQL Serverは貧弱</li>
<li>今はあるがMulti-AZも無かったし、ProvisionedIOPSの限界値も低かった</li>
<li>結果、MySQLを使っている</li>
</ul>
</li>
</ul>


<p>r3.8xlargeが最強</p>

<p>垂直分割 vs 水平分割</p>

<p>機能単位の垂直分割を採用</p>

<p>水平分割は避ける: 記述可能なクエリに大きな制限がかかってしまう アドホックなクエリでの集計が不可能になる
ほとんどのアプリケーションは、水平分割をする必要はないのでは？</p>

<p>DB管理はGUIで
HeidiSQLがおすすめ　phpMyAdminやCUIは積極的にdisりたい</p>

<p>アプリケーションからはMasterのみ参照
いまどきのRDSは十分パワフルなので、Slaveに分散するのは無用な複雑さを生むだけ
レプリケーション遅延は起きるので。</p>

<p>同一AZに配置する
AZを越えると普段0.5msec程度のクエリが2msec程度になる</p>

<p>C#的な活用としては、コネクションを型で分けるとコンパイルでチェックできる
生のSQLを書いている</p>

<p>テーブル定義から自動生成
テーブルと1:1でひもづいたクラスがある
T4テンプレート + ADO.net</p>

<p>半自動生成くらいの位置づけ</p>

<ul>
<li><p>全階層でのキャッシュの徹底</p>

<ul>
<li>データベース</li>
<li>Memcache-Redis</li>
<li>Static変数: アイテム名など不変の情報はキャッシュ　</li>
<li>リクエスト単位</li>
</ul>
</li>
</ul>


<p>アプリケーションコードによるJOIN</p>

<p>LINQ to Objectsで簡単。SQLよりもずっと楽</p>

<h2>Redis</h2>

<p>RDSの不得意な部分を補える
高パフォーマンスなのでMemcached代わりのキャッシュ用途に
用途ごとのグループ分けと単純分散</p>

<p>Master Slave構成をとっている
dump出力時にCPUをくうので</p>

<p>ElastiCache Redisは試したときにパフォーマンスがでなかったので使っていない</p>

<p>Protocol Buffersを使っている
高速・省サイズなので</p>

<h2>Performance + Async</h2>

<p>100msecを切るように作っている
C# 5.0を活用</p>

<p>言語構文レベルでサポートされる非同期
同期と同じように非同期が書ける Graniではコード全体が非同期で書かれている</p>

<p>Redisならパイプライン化可能
全てが非同期で自動でパイプライン化される</p>

<p>性能と設計を両立できる</p>

<h2>Log for performance</h2>

<p>外部通信を全て記録する
アプリケーション側で送信前後をフックして記録
後述するGlimpseやSumo Logicで解析する
アプリ側でやると負荷がない</p>

<h3>Glimpse &ndash; 可視化</h3>

<p>全体の実行時間のほか、あらゆるメトリックスを常時可視化
<a href="http://getglimpse.com">http://getglimpse.com</a></p>

<p>Explainの常時表示　手動でExplainはやらない
Redis送受信の表示</p>

<h3>日常的開発</h3>

<p>Git + GitHub
Jenkins
DeployはValentia(自社ツール)</p>

<p>Sumo Logicでログ解析
New Relicでモニタリング</p>

<p>Semantic Logging + Redshift + Tableau
<a href="http://slab.codeplex.com">http://slab.codeplex.com</a></p>

<h2>まとめ</h2>

<ul>
<li>C# + AWSは現実界</li>
<li>構成は堅く、シンプルに</li>
<li>環境は常に最新に</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: Amazon CloudFrontを利用したサイト高速化およびセキュア配信]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-cloudfront/"/>
    <updated>2014-07-18T12:21:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/18/aws-summit-tokyo-2014-cloudfront</id>
    <content type="html"><![CDATA[<p>ソリューションアーキテクトの北迫さんによる、Cloudfrontの活用方法についてです。</p>

<p>普段RTBをやっているので、相手はユーザーのブラウザではなくてSSPやアドネットワークのAPIで、普段CDNを意識することはあまりありません。
バナー広告の画像やJavaScriptを置いているくらいです。
将来、動画配信とかするなら詳しくなっておきたいなと・・・</p>

<p>ただ現時点でも、劇的にコストや負荷を軽減する方法として、CDNとしてのCloudfrontにはまだ利用シーンがあるのではと思って考えています。</p>

<h2>サイト高速化</h2>

<p>DNSの仕組みを使って最適なエッジへ誘導
52 Edge locations</p>

<p>80:20の法則
ページ本体のレスポンスタイムは20%に過ぎず、それ以外の部分に80%の時間を使っている</p>

<p>ispとispの間のixのところから足が生える形でAWS edgeがある</p>

<h3>CDN Edge Locationの活用</h3>

<p>分散型CDNと集中型のCDN</p>

<p>分散型CDN: ユーザーに近いISPのところにEdgeがある キャッシュヒット率が低い傾向
集中型CDN: キャッシュ共有 Cloudfrontはこちら</p>

<p>CloudfrontのEdgeに可能な限りキャッシュさせることが重要</p>

<ul>
<li><p>静的コンテンツ 805
キャッシュTTLも可能な限り長く、クライアント側にもキャッシュさせる</p></li>
<li><p>動的コンテンツ 20%</p>

<ul>
<li>ページ共通のもの</li>
<li>パーソナライズされたもの

<ul>
<li>動的に生成されるが、ページ自体は一定期間共通 QueryStringを活用しているもの</li>
<li>HTTPヘッダによるページ切り替えしているもの</li>
<li>cache-conrtol headerとminimum ttlで調整</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>キャッシュしすぎるとEdgeを通すオーバーヘッドはないか？
last-modified/ETag ヘッダ
if-modified-since 更新なしなら304を返す</p>

<ul>
<li><p>ヒット率向上のための要素</p>

<ul>
<li>キャッシュ時間</li>
<li>URLの共通化</li>
<li>Etag/Last-modifiedヘッダの活用</li>
<li>Query Stringsパラメータの固定化</li>
<li>転送対象Header値の固定化</li>
</ul>
</li>
<li><p>Cloudfrontは完全一致でキャッシュを共有</p></li>
<li><p>キャッシュヒット状況はレスポンスヘッダで</p>

<ul>
<li>X-Cacheの値を見る</li>
<li>X-Amz-Cf-IdにIDが入る</li>
</ul>
</li>
</ul>


<p>キャッシュができない動的ページはプロキシとして利用</p>

<p>Dynamic Contens Acceleration</p>

<ul>
<li>Post/Put/Header/Cookie対応</li>
</ul>


<p>CloudfrontのEdgeを経由させても多くの動的ページが扱えるようになった</p>

<ul>
<li>Keep-Alive Connection:  3 way handshakeのカット</li>
</ul>


<p>CDN &ndash; Originの間でKeepAliveする
HTTPS通信ならSSL Terminationでより効果が大きい</p>

<ul>
<li>TCPスロースタート</li>
</ul>


<p>ネットワークの輻輳を回避するために少しつづパケットを増やしながら量を増やしていく仕組み</p>

<ul>
<li>DNS Lookupの高速化</li>
</ul>


<p>Route53を活用するとLookupが早くなる: Cloudfrontと同じロケーションにサーバーがある &ndash;> 近い
CloudfrontはAlternative Domain Name: レコードセットのTypeをCNAMEではなくAレコードのエイリアスを利用することでクエリ回数の削減が可能</p>

<p>Cloudfront behaviorの活用
正規表現でURL毎に異なるキャッシュポリシーを適用できる
オリジンサーバーのほうで設定をする必要がない　</p>

<h2>セキュア配信</h2>

<ul>
<li><p>Httpsサポート</p></li>
<li><p>GEO Restriction</p></li>
<li><p>Signed URL(署名付きURL)</p>

<ul>
<li>Cloudfront経由で配信するコンテンツに対して期間指定URLを生成することで、配信コンテンツを保護する機能</li>
<li>ポリシーを指定する</li>
<li>Origin Access Identity(OAI)を使うと特定のCloudfrontからしかアクセスできないようにできる。一般のサーバーから制限する場合はIPアドレスで(CloudfrontのIPは公開されている)</li>
<li>プレミアムコンテンツ配信, Streaming配信などに利用</li>
<li>有効時間の設定は、ダウンロードならサイズにかかわらず短時間でOK　ストリーミングは映像・音声の再生時間+αを設定</li>
<li>Behavior毎の設定、正規表現を利用してDistributionを分けなくても特定のコンテンツのみ保護可能</li>
<li>Cache-controlヘッダも同様に利用できる</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<ul>
<li>インフラアプローチでの高速化施策</li>
<li>動的コンテンツにもうまく活用できる</li>
<li>セキュアなコンテンツ配信も容易かつ高速化が可能</li>
</ul>


<p>2014/9/9 AWS Cloud Strage &amp; DB Day
<a href="http://csd.awseventsjapan.com">http://csd.awseventsjapan.com</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Summit Tokyo 2014: Amazon Redshiftによるリアルタイム分析サービスの構築]]></title>
    <link href="http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad/"/>
    <updated>2014-07-17T13:08:00+09:00</updated>
    <id>http://chokkoyamada.github.io/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad</id>
    <content type="html"><![CDATA[<p>Cookpadのエンジニアの青木さんによる、Redshiftの活用方法です。　</p>

<p>さきほどのEMRのセッションも聞きつつも、SQLの世界は深いので、まだまだSQLで頑張れる部分はたくさんあるのではないかと思っています。
Redshiftで可能なことのごく一部しか使っておらず、「Redshiftじゃきつい」というレベルにもまだないです。</p>

<p>ただ、いうほど”リアルタイム”ではなかったです。ユーザーからの検索はリアルタイムで直接SELECTしているみたいですが、データ更新はバッチ処理でした。</p>

<p>User &ndash; EC2 &ndash; Redshiftという構成になっているのが一番驚きました。「たべみる」がB2Bサービスなのでそれほど同時に使う人数が多くないのでしょうが、こういう構成は無理かなと思い込んでいたのでとても参考になりました。</p>

<h2>たべみる: 検索システム</h2>

<ul>
<li>単語の検索頻度</li>
<li>単語の組み合わせ頻度</li>
<li>現在盛り上がっている単語</li>
<li>ユーザーの年代や居住地域を軸とした分析</li>
</ul>


<p>「バレンタイン」のキーワード分析　単語の組み合わせ　マッチ度　バレンタイン + 本命, 簡単, 大量</p>

<h2>たべみるのシステム構成</h2>

<p>User &ndash; ELB &ndash; EC2 &ndash; Redshift</p>

<p>Rails4 / Ruby2.1
dw2.large x 12</p>

<p>目標応答時間 500msec</p>

<p>応答速度向上の施策
圧縮タイプの選択
sort key: where句で入れているものは全てSort Keyに入れる 大きく削るならDist Key, 細かいチューニングはSort key
サマリーテーブル: 大きいデータをクエリすると絶対に時間かかるので、サマっておく</p>

<p>サマリーテーブルいつ作る？
安心と伝統の夜間バッチ 37minで実行できているのでHourlyの更新も可能だが、あえてやっていない。不要なので。
B2Bサービスなので、1日に少しずつ追加されてもあまり意味が無いため。</p>

<p>ログまたはMySQL &ndash;> file &ndash;> Redhisft(raw &ndash;> 中間データ &ndash;> summaryの三段階)</p>

<h2>データ連携の詳細</h2>

<p>信頼と実績のTSV渡し</p>

<p>他の用途ではfluentdによる継続ロードも</p>

<h2>SQLによるデータ処理</h2>

<ul>
<li><p>ELTのお約束</p>

<ul>
<li>エクスポート禁止:　データ移動は遅い　 DB外処理は非並列</li>
<li>UPDATE禁止:  複数回実行しにくい(冪等にしておきたい) VACUUMが厄介</li>
<li>1行INSERT禁止:  COPYかINSERT SELECT</li>
</ul>
</li>
<li><p>INSERT SELECTだけ使え！！</p></li>
<li><p>SQLでは書けなかった処理</p>

<ul>
<li>日本語処理　半角→全角変換</li>
<li>可変数カラム　タブ区切り文字列の分割</li>
<li>要するに文字列処理がきつい</li>
</ul>
</li>
<li><p>SQLで書ける！ こんな処理</p>

<ul>
<li>単語の組み合わせ生成  ジョイン</li>
<li>未来の月曜日N週ぶんの生成 ジョイン</li>
<li>テーブルの縦横変換 ジョイン</li>
<li>移動平均、移動累積和 ウィンドウ関数</li>
<li>グループごとのランキングTOPN ウィンドウ関数</li>
</ul>
</li>
<li><p>テーブルの縦横変換の例</p></li>
<li>グループごとのランキングの例 ウィンドウ関数を使うと、分割するけど、これを集約せずに結果だけ取ることができる

<ul>
<li>rank() over ( partition by ~ order by ~)</li>
</ul>
</li>
</ul>


<h2>データ更新のパターン</h2>

<ul>
<li><p>差分更新</p>

<ul>
<li>追加されたデータだけ更新する</li>
<li>デメリットは、冪等にしくくいこと</li>
<li>そのため、あらかじめ生成されるレンジのデータを消してからデータを挿入する処理にする</li>
</ul>
</li>
<li><p>洗い替え</p>

<ul>
<li>dropまたはtruncateして作りなおす</li>
<li>差分を考える必要がない</li>
<li>遅い</li>
<li>新しいテーブルを作ると権限(GRANT)を1個1個つけて回る必要があり、面倒</li>
<li>VACUUM問題</li>
</ul>
</li>
<li><p>アトミック洗い替え</p>

<ul>
<li>新しいテーブルを作ってる途中にテーブルが無くなってしまうので、テーブルが作り終わってからTRANSACTION内でALTER TABLE RENAMEする</li>
<li>24時間参照するテーブルではこれを使う</li>
<li>デメリットとしては、データが2倍になってしまう</li>
</ul>
</li>
<li><p>応用：アトミックな本番切り替え</p>

<ul>
<li>複数のテーブルをいっぺんに切り替える</li>
<li>複数のテーブルがお互いにデータが関連している場合</li>
</ul>
</li>
<li><p>更新パターンの使い分け</p>

<ul>
<li>生データは差分更新</li>
<li>中間データは洗い替え</li>
<li>サマリーデータはアトミック洗い替え</li>
</ul>
</li>
</ul>


<h2>なぜRedshiftにしたのか</h2>

<ul>
<li>COOKPADがAWSにあるから</li>
<li>マネージドサービスだから</li>
<li>並列処理能力が高いから</li>
<li>ウィンドウ関数など高度な機能が実装されているから</li>
<li>ある程度オンライン処理にも耐えられるから</li>
</ul>

]]></content>
  </entry>
  
</feed>
