
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Continuous Ops</title>
  <meta name="author" content="Naoyuki Yamada">

  
  <meta name="description" content="ソリューションアーキテクトの大谷さんと開発マネージャの堀さんによる、Kinesisの詳説です。
Kinesisの開発マネージャの方が解説してくれたこともあり、とても意義あるものでした。 Kinesisの新規ローンチ 東京リージョンローンチ
Fluentdプラグイン https://github. &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://chokkoyamada.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Continuous Ops" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-41056307-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Continuous Ops</a></h1>
  
    <h2>Exploring the world of 'Infrastructure as Code'</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:chokkoyamada.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/18/aws-summit-tokyo-2014-kinesis-deep-dive/">AWS Summit Tokyo 2014: Amazon Kinesis Deep Dive</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-18T15:10:00+09:00" pubdate data-updated="true">Jul 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>ソリューションアーキテクトの大谷さんと開発マネージャの堀さんによる、Kinesisの詳説です。
Kinesisの開発マネージャの方が解説してくれたこともあり、とても意義あるものでした。</p>

<h3>Kinesisの新規ローンチ</h3>

<ul>
<li>東京リージョンローンチ</li>
<li>Fluentdプラグイン <a href="https://github.com/awslabs/aws-fluent-plugin-kinesis">https://github.com/awslabs/aws-fluent-plugin-kinesis</a></li>
<li>MQTTアダプター <a href="https://github.com/awslabs/mqtt-kinesis-bridge">https://github.com/awslabs/mqtt-kinesis-bridge</a></li>
</ul>


<h2>事例紹介</h2>

<ul>
<li>ガリバー <a href="http://221616.com/gulliver/news/press/20140715-13667.html">http://221616.com/gulliver/news/press/20140715-13667.html</a></li>
<li>Pencil(リアルタイムユーザーモニター)</li>
<li>SmartInsight(Beaconとの距離をロギング)</li>
<li>Supercell</li>
<li>bizo</li>
</ul>


<h2>Kinesis詳細</h2>

<h3>なぜリアルタイム？</h3>

<ul>
<li>測定(Metering)サービス　使った分だけ課金されるという特性　オペレーションを測定しないといけない</li>
<li>毎秒数千万レコード</li>
<li>毎時数テラバイト</li>
<li>数十万のデータ・ソース</li>
<li><p>月末にはオーディターでの100%の正確性</p></li>
<li><p>毎時数百万のファイル</p></li>
<li>スケールの課題</li>
<li>リアルタイムの要望</li>
<li><p>高い運用コスト</p></li>
<li><p>要求の変化
毎時か毎日のデータ処理が従来の要求だったが、リアルタイム、早い意思決定、KeepEverything、エラスティックな拡張性、複数の目的に応じて同じデータを並行処理したい、などの新しい要求が出てきた。</p></li>
</ul>


<h3>Kinesis概要</h3>

<p>用途単位でStreamを作成し、Streamは１つ以上のShardで構成される
Shardは入力側秒間１MB 1000TPB 出力側2mB, ５TPSのキャパシティ
入力されたデータは複数のAZに２４時間保存
Shardの増減でスケール</p>

<h3>データ入力</h3>

<p>HTTPS/POSt
SDK
Fluentd
Flume
Log4J
etc</p>

<p>ProducerがPut Recordするサンプル AWS CLIでできる</p>

<p>Shardへの分配ロジック：　md5でハッシュ化して該当のShardに分配される
パーティションキーを何にするかは重要</p>

<p>パーティションキーの数 > shardの数
カーディナリティーの高いパーティションキーを使う</p>

<p>シーケンス番号を使って何度でも読むことができる
何度取得してもシーケンス番号の順番は変わらない:重要</p>

<p>データ取得と処理</p>

<p>API
Kinesis Client Library/ConnectorLibrary
Storm
EMR</p>

<h2>どうやって信頼性と拡張性のあるアプリケーションを作るの？</h2>

<ul>
<li>Kinesis Client Libraryを提供

<ul>
<li>Shardと同じ数のWorker</li>
<li>Workerを均等にロードバランシング</li>
<li>障害完治と新しいWorkerの立ち上げ</li>
<li>shardの数に応じてWorkerが動作する</li>
<li>Autoscaling</li>
<li>チェックポインティング、At least once処理</li>
</ul>
</li>
</ul>


<p>これらの煩雑な処理を意識することなく、ビジネスロジックに集中できる</p>

<h3>重複データについて</h3>

<p>ネットワーク障害や500レベルエラーはリトライをする
リカバリやロードバランシングでデータが最後のチェックポイントからリプレイされる</p>

<ul>
<li>ユースケースを理解する

<ul>
<li>冪等なアプリをつくる</li>
<li>重複を許容する</li>
</ul>
</li>
</ul>


<h3>Kinesis Connector Library</h3>

<p>S3, DynamoDB, Redshift
4つのインタフェースを使うと簡単に書ける</p>

<p>1つのデータをいろいろなシステムで
プロデューサーの負荷軽減
データの一貫性を保ちたい</p>

<p>Kinesisに全てのデータを１回入力する
必要に応じて新しいアプリを追加していく
Agilityを高める</p>

<h2>Elasticな拡張性</h2>

<ul>
<li>Streamは１つ以上のキャパシティで構成　Shardでキャパシティプランニング</li>
<li>SplitShard API Shardを半分に分割</li>
</ul>


<p>shardやEC2もキャパシティがある
ProvisionedThroughputExceededException</p>

<p>shard１つで14$/month
Getトランザクションは無料</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/18/aws-summit-tokyo-2014-dynamo-kinesis/">AWS Summit Tokyo 2014: Amazon Kinesisを用いたリアルタイムのゲーム分析システムと、AWS ElasticBeanstalk＆Amazon DynamoDB を活用したゲーム運営</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-18T14:15:00+09:00" pubdate data-updated="true">Jul 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Ripplationという会社の安藤さんと立本さんによるゲーム運営にAWSのマネージドサービスを活用する話です。
最近のゲーム界隈にうといのですが、「騎士とドラゴン」が代表的タイトルですかね。</p>

<p>とことん運用を楽にする側に振り切っているのは清々とします。</p>

<p>Kinesis &ndash; ElasticBeansTalk &ndash; S3の組み合わせ方がかなり独特で、二段階に処理を分けるというのはとてもおもしろいと思いました</p>

<ul>
<li>いかにして最小人数でサーバー側の開発を行うか</li>
<li><p>以下にしてサーバーコストを下げるか</p></li>
<li><p>スケール・耐障害の自動化</p></li>
<li>監視システムも簡単にしたい</li>
</ul>


<p>なので、ElasticBeansTalk + DynamoDBのみで構成することにした</p>

<h2>AWSを使ってみてわかったこと</h2>

<ul>
<li>すぐ始められる</li>
<li>アプリをサーバーにデプロイするまでに流れを作るのが簡単</li>
<li>1から整える必要がない</li>
<li>思った以上に実用に耐えられる</li>
<li>ほとんど放置が可能: 最近サーバーをコンソールで調整したくらい</li>
</ul>


<h3>ElasticBeansTalkの注意点</h3>

<ul>
<li>デプロイ時に一瞬アクセスできないことがある: 気にせずデプロイしている。エラー処理はアプリケーション側で行っている</li>
<li>オートスケーリングの調整はきっちりしておく</li>
</ul>


<h3>DynamoDBの注意点</h3>

<ul>
<li>社内にいるDB技術者の文句やいちゃもんに負けない　問題が出たら後付けで</li>
<li>バッチ処理をしっかり使う、リトライも行う</li>
<li>スループットの限界値は急激に変化させられない: 急激な書き込みは読み込みはできない</li>
<li>バックアップするかどうか　リストアする場合ってどんな状況だろうか</li>
</ul>


<h3>汎用化なんて考えたらダメ</h3>

<ul>
<li>AWSを使い倒さないと真の良さは発揮されない</li>
<li>そんなにどれでも動く仕組みって重要なんでしょうか。</li>
</ul>


<h2>ログデータの収集・集計</h2>

<ul>
<li>結局、最初はDynamoDBだけでなんとかした</li>
</ul>


<h2>KinesisとBigData</h2>

<h3>ビッグデータとはなにか</h3>

<p>単体ではよくわからないデータこそがビッグデータ</p>

<p>達成課題：毎秒10万件のデータを収集する</p>

<p>Linux
TCP
28000個ぐらいのポート
TIMEWAIT 60sec
実測値への縫製係数: 0.6
1server 282 req/sec</p>

<p>チューニング後：</p>

<p>Linux
TCP
64000 Port
TIMEWAIT 10sec
1server 4000req/sec</p>

<p>26台あれば　 3870x26=100620req/sec</p>

<p>ただ、これをどうやって集める？ 一般的なサーバーでつくろうとするとdisaster recovery含めて大変</p>

<p>Kinesisならシャードを100個立てれば終了</p>

<p>Grasslandというツールを開発中: データを分析して</p>

<h2>GrasslandでのKinesisの使いどころ</h2>

<p>1 クライアントからはKinesisにデータを直接投げる
2 ElasticBeansTalkはS3にキャシュを保存
3 S3はcacheの解析リクエストをKinesisに返す
4 Kinesis &ndash;> EBT に解析リクエストを投げる
5 S3 &ndash;> EBT はキャッシュを返す
6 EBT &ndash;> S3 解析結果を渡す</p>

<p>セキュリティを担保できる工夫はいろいろできる</p>

<p>Kinesisは世界のデータを集めるように作られている</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/18/aws-summit-tokyo-2014-grani-windows/">AWS Summit Tokyo 2014: AWS + Windows(C#)で構築する.NET最先端技術によるハイパフォーマンスウェブアプリケーション開発実践</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-18T13:19:00+09:00" pubdate data-updated="true">Jul 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>ソーシャルゲームデベロッパーのGraniの河合さんによるC#のウェブアプリケーションの解説です。</p>

<p>私はWindowsでアプリケーションを書いたことも運用したこともないのですが、かなり昔にMS-DOSでシステム管理は少しやったことがあるので、Microsoftの技術には愛着を持っています。</p>

<p>一番驚いたのは、C#の機能をを活かして処理をほぼ非同期で行っているというところでした。
PHPなどでは絶対無理な処理なので、これはすごいなと。
私のプロダクトでやるならScalaになるのでしょうが、ここまでの境地に達するのはよほど言語に精通していないといけない気がします。</p>

<p>ソーシャルゲームのレスポンスで全て100msecを切るように返すことの大変さは分かっているつもりなので、レベルの違いを感じました。
Redisのパイプライン処理いいですね。</p>

<p>とにかくクールだなと思いました。ひたすら感心。</p>

<p>門外漢のC#やWindowsの話をあえて聞いてみてよかったです。</p>

<ul>
<li>AWS + C#によるウェブソーシャルゲーム</li>
<li>C# 50%, AWS 20%, その他 30%ぐらいの話</li>
<li>AWSだからといってC#を使うのに特別なことはない</li>
</ul>


<h2>using CSharp;</h2>

<ul>
<li>C#の開発にとことんこだわっている</li>
<li>もとはPHPだったが開発効率に不満を感じた</li>
<li>半年後にC#に全面移行</li>
<li><p>AWSを使っていたのでそのまま移行した</p></li>
<li><p>クライアントサイドからサーバーサイドまで全てをC#で！</p></li>
</ul>


<p>AWS + C#は全く問題ない。</p>

<ul>
<li>100 server</li>
<li>10000 req/sec</li>
<li>1000000000pv/day</li>
</ul>


<p>IIS8 + RDS + Redis(r3.2xlarge)20台</p>

<h2>なぜRDBMSを選択するのか</h2>

<ul>
<li>NoSQLでいい？けれど複雑化をおさえたい</li>
<li>RDBMSは単純なクエリなら1msec以下で返すがDynamoDBは・・・</li>
<li>周辺ツールが充実</li>
<li>スケールアップや分割で対応できるなら、スケールアウトに固執することもない</li>
</ul>


<h3>何よりRDSが良い</h3>

<p>手放し管理、Restore To Point in Timeには救われた</p>

<ul>
<li>SQL Server vs MySQL

<ul>
<li>C#としてはSQL Serverのほうが相性はいい</li>
<li>しかしRDSとしてみるとSQL Serverは貧弱</li>
<li>今はあるがMulti-AZも無かったし、ProvisionedIOPSの限界値も低かった</li>
<li>結果、MySQLを使っている</li>
</ul>
</li>
</ul>


<p>r3.8xlargeが最強</p>

<p>垂直分割 vs 水平分割</p>

<p>機能単位の垂直分割を採用</p>

<p>水平分割は避ける: 記述可能なクエリに大きな制限がかかってしまう アドホックなクエリでの集計が不可能になる
ほとんどのアプリケーションは、水平分割をする必要はないのでは？</p>

<p>DB管理はGUIで
HeidiSQLがおすすめ　phpMyAdminやCUIは積極的にdisりたい</p>

<p>アプリケーションからはMasterのみ参照
いまどきのRDSは十分パワフルなので、Slaveに分散するのは無用な複雑さを生むだけ
レプリケーション遅延は起きるので。</p>

<p>同一AZに配置する
AZを越えると普段0.5msec程度のクエリが2msec程度になる</p>

<p>C#的な活用としては、コネクションを型で分けるとコンパイルでチェックできる
生のSQLを書いている</p>

<p>テーブル定義から自動生成
テーブルと1:1でひもづいたクラスがある
T4テンプレート + ADO.net</p>

<p>半自動生成くらいの位置づけ</p>

<ul>
<li><p>全階層でのキャッシュの徹底</p>

<ul>
<li>データベース</li>
<li>Memcache-Redis</li>
<li>Static変数: アイテム名など不変の情報はキャッシュ　</li>
<li>リクエスト単位</li>
</ul>
</li>
</ul>


<p>アプリケーションコードによるJOIN</p>

<p>LINQ to Objectsで簡単。SQLよりもずっと楽</p>

<h2>Redis</h2>

<p>RDSの不得意な部分を補える
高パフォーマンスなのでMemcached代わりのキャッシュ用途に
用途ごとのグループ分けと単純分散</p>

<p>Master Slave構成をとっている
dump出力時にCPUをくうので</p>

<p>ElastiCache Redisは試したときにパフォーマンスがでなかったので使っていない</p>

<p>Protocol Buffersを使っている
高速・省サイズなので</p>

<h2>Performance + Async</h2>

<p>100msecを切るように作っている
C# 5.0を活用</p>

<p>言語構文レベルでサポートされる非同期
同期と同じように非同期が書ける Graniではコード全体が非同期で書かれている</p>

<p>Redisならパイプライン化可能
全てが非同期で自動でパイプライン化される</p>

<p>性能と設計を両立できる</p>

<h2>Log for performance</h2>

<p>外部通信を全て記録する
アプリケーション側で送信前後をフックして記録
後述するGlimpseやSumo Logicで解析する
アプリ側でやると負荷がない</p>

<h3>Glimpse &ndash; 可視化</h3>

<p>全体の実行時間のほか、あらゆるメトリックスを常時可視化
<a href="http://getglimpse.com">http://getglimpse.com</a></p>

<p>Explainの常時表示　手動でExplainはやらない
Redis送受信の表示</p>

<h3>日常的開発</h3>

<p>Git + GitHub
Jenkins
DeployはValentia(自社ツール)</p>

<p>Sumo Logicでログ解析
New Relicでモニタリング</p>

<p>Semantic Logging + Redshift + Tableau
<a href="http://slab.codeplex.com">http://slab.codeplex.com</a></p>

<h2>まとめ</h2>

<ul>
<li>C# + AWSは現実界</li>
<li>構成は堅く、シンプルに</li>
<li>環境は常に最新に</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/18/aws-summit-tokyo-2014-cloudfront/">AWS Summit Tokyo 2014: Amazon CloudFrontを利用したサイト高速化およびセキュア配信</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-18T12:21:00+09:00" pubdate data-updated="true">Jul 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>ソリューションアーキテクトの北迫さんによる、Cloudfrontの活用方法についてです。</p>

<p>普段RTBをやっているので、相手はユーザーのブラウザではなくてSSPやアドネットワークのAPIで、普段CDNを意識することはあまりありません。
バナー広告の画像やJavaScriptを置いているくらいです。
将来、動画配信とかするなら詳しくなっておきたいなと・・・</p>

<p>ただ現時点でも、劇的にコストや負荷を軽減する方法として、CDNとしてのCloudfrontにはまだ利用シーンがあるのではと思って考えています。</p>

<h2>サイト高速化</h2>

<p>DNSの仕組みを使って最適なエッジへ誘導
52 Edge locations</p>

<p>80:20の法則
ページ本体のレスポンスタイムは20%に過ぎず、それ以外の部分に80%の時間を使っている</p>

<p>ispとispの間のixのところから足が生える形でAWS edgeがある</p>

<h3>CDN Edge Locationの活用</h3>

<p>分散型CDNと集中型のCDN</p>

<p>分散型CDN: ユーザーに近いISPのところにEdgeがある キャッシュヒット率が低い傾向
集中型CDN: キャッシュ共有 Cloudfrontはこちら</p>

<p>CloudfrontのEdgeに可能な限りキャッシュさせることが重要</p>

<ul>
<li><p>静的コンテンツ 805
キャッシュTTLも可能な限り長く、クライアント側にもキャッシュさせる</p></li>
<li><p>動的コンテンツ 20%</p>

<ul>
<li>ページ共通のもの</li>
<li>パーソナライズされたもの

<ul>
<li>動的に生成されるが、ページ自体は一定期間共通 QueryStringを活用しているもの</li>
<li>HTTPヘッダによるページ切り替えしているもの</li>
<li>cache-conrtol headerとminimum ttlで調整</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>キャッシュしすぎるとEdgeを通すオーバーヘッドはないか？
last-modified/ETag ヘッダ
if-modified-since 更新なしなら304を返す</p>

<ul>
<li><p>ヒット率向上のための要素</p>

<ul>
<li>キャッシュ時間</li>
<li>URLの共通化</li>
<li>Etag/Last-modifiedヘッダの活用</li>
<li>Query Stringsパラメータの固定化</li>
<li>転送対象Header値の固定化</li>
</ul>
</li>
<li><p>Cloudfrontは完全一致でキャッシュを共有</p></li>
<li><p>キャッシュヒット状況はレスポンスヘッダで</p>

<ul>
<li>X-Cacheの値を見る</li>
<li>X-Amz-Cf-IdにIDが入る</li>
</ul>
</li>
</ul>


<p>キャッシュができない動的ページはプロキシとして利用</p>

<p>Dynamic Contens Acceleration</p>

<ul>
<li>Post/Put/Header/Cookie対応</li>
</ul>


<p>CloudfrontのEdgeを経由させても多くの動的ページが扱えるようになった</p>

<ul>
<li>Keep-Alive Connection:  3 way handshakeのカット</li>
</ul>


<p>CDN &ndash; Originの間でKeepAliveする
HTTPS通信ならSSL Terminationでより効果が大きい</p>

<ul>
<li>TCPスロースタート</li>
</ul>


<p>ネットワークの輻輳を回避するために少しつづパケットを増やしながら量を増やしていく仕組み</p>

<ul>
<li>DNS Lookupの高速化</li>
</ul>


<p>Route53を活用するとLookupが早くなる: Cloudfrontと同じロケーションにサーバーがある &ndash;> 近い
CloudfrontはAlternative Domain Name: レコードセットのTypeをCNAMEではなくAレコードのエイリアスを利用することでクエリ回数の削減が可能</p>

<p>Cloudfront behaviorの活用
正規表現でURL毎に異なるキャッシュポリシーを適用できる
オリジンサーバーのほうで設定をする必要がない　</p>

<h2>セキュア配信</h2>

<ul>
<li><p>Httpsサポート</p></li>
<li><p>GEO Restriction</p></li>
<li><p>Signed URL(署名付きURL)</p>

<ul>
<li>Cloudfront経由で配信するコンテンツに対して期間指定URLを生成することで、配信コンテンツを保護する機能</li>
<li>ポリシーを指定する</li>
<li>Origin Access Identity(OAI)を使うと特定のCloudfrontからしかアクセスできないようにできる。一般のサーバーから制限する場合はIPアドレスで(CloudfrontのIPは公開されている)</li>
<li>プレミアムコンテンツ配信, Streaming配信などに利用</li>
<li>有効時間の設定は、ダウンロードならサイズにかかわらず短時間でOK　ストリーミングは映像・音声の再生時間+αを設定</li>
<li>Behavior毎の設定、正規表現を利用してDistributionを分けなくても特定のコンテンツのみ保護可能</li>
<li>Cache-controlヘッダも同様に利用できる</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<ul>
<li>インフラアプローチでの高速化施策</li>
<li>動的コンテンツにもうまく活用できる</li>
<li>セキュアなコンテンツ配信も容易かつ高速化が可能</li>
</ul>


<p>2014/9/9 AWS Cloud Strage &amp; DB Day
<a href="http://csd.awseventsjapan.com">http://csd.awseventsjapan.com</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad/">AWS Summit Tokyo 2014: Amazon Redshiftによるリアルタイム分析サービスの構築</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-17T13:08:00+09:00" pubdate data-updated="true">Jul 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Cookpadのエンジニアの青木さんによる、Redshiftの活用方法です。　</p>

<p>さきほどのEMRのセッションも聞きつつも、SQLの世界は深いので、まだまだSQLで頑張れる部分はたくさんあるのではないかと思っています。
Redshiftで可能なことのごく一部しか使っておらず、「Redshiftじゃきつい」というレベルにもまだないです。</p>

<p>ただ、いうほど”リアルタイム”ではなかったです。ユーザーからの検索はリアルタイムで直接SELECTしているみたいですが、データ更新はバッチ処理でした。</p>

<p>User &ndash; EC2 &ndash; Redshiftという構成になっているのが一番驚きました。「たべみる」がB2Bサービスなのでそれほど同時に使う人数が多くないのでしょうが、こういう構成は無理かなと思い込んでいたのでとても参考になりました。</p>

<h2>たべみる: 検索システム</h2>

<ul>
<li>単語の検索頻度</li>
<li>単語の組み合わせ頻度</li>
<li>現在盛り上がっている単語</li>
<li>ユーザーの年代や居住地域を軸とした分析</li>
</ul>


<p>「バレンタイン」のキーワード分析　単語の組み合わせ　マッチ度　バレンタイン + 本命, 簡単, 大量</p>

<h2>たべみるのシステム構成</h2>

<p>User &ndash; ELB &ndash; EC2 &ndash; Redshift</p>

<p>Rails4 / Ruby2.1
dw2.large x 12</p>

<p>目標応答時間 500msec</p>

<p>応答速度向上の施策
圧縮タイプの選択
sort key: where句で入れているものは全てSort Keyに入れる 大きく削るならDist Key, 細かいチューニングはSort key
サマリーテーブル: 大きいデータをクエリすると絶対に時間かかるので、サマっておく</p>

<p>サマリーテーブルいつ作る？
安心と伝統の夜間バッチ 37minで実行できているのでHourlyの更新も可能だが、あえてやっていない。不要なので。
B2Bサービスなので、1日に少しずつ追加されてもあまり意味が無いため。</p>

<p>ログまたはMySQL &ndash;> file &ndash;> Redhisft(raw &ndash;> 中間データ &ndash;> summaryの三段階)</p>

<h2>データ連携の詳細</h2>

<p>信頼と実績のTSV渡し</p>

<p>他の用途ではfluentdによる継続ロードも</p>

<h2>SQLによるデータ処理</h2>

<ul>
<li><p>ELTのお約束</p>

<ul>
<li>エクスポート禁止:　データ移動は遅い　 DB外処理は非並列</li>
<li>UPDATE禁止:  複数回実行しにくい(冪等にしておきたい) VACUUMが厄介</li>
<li>1行INSERT禁止:  COPYかINSERT SELECT</li>
</ul>
</li>
<li><p>INSERT SELECTだけ使え！！</p></li>
<li><p>SQLでは書けなかった処理</p>

<ul>
<li>日本語処理　半角→全角変換</li>
<li>可変数カラム　タブ区切り文字列の分割</li>
<li>要するに文字列処理がきつい</li>
</ul>
</li>
<li><p>SQLで書ける！ こんな処理</p>

<ul>
<li>単語の組み合わせ生成  ジョイン</li>
<li>未来の月曜日N週ぶんの生成 ジョイン</li>
<li>テーブルの縦横変換 ジョイン</li>
<li>移動平均、移動累積和 ウィンドウ関数</li>
<li>グループごとのランキングTOPN ウィンドウ関数</li>
</ul>
</li>
<li><p>テーブルの縦横変換の例</p></li>
<li>グループごとのランキングの例 ウィンドウ関数を使うと、分割するけど、これを集約せずに結果だけ取ることができる

<ul>
<li>rank() over ( partition by ~ order by ~)</li>
</ul>
</li>
</ul>


<h2>データ更新のパターン</h2>

<ul>
<li><p>差分更新</p>

<ul>
<li>追加されたデータだけ更新する</li>
<li>デメリットは、冪等にしくくいこと</li>
<li>そのため、あらかじめ生成されるレンジのデータを消してからデータを挿入する処理にする</li>
</ul>
</li>
<li><p>洗い替え</p>

<ul>
<li>dropまたはtruncateして作りなおす</li>
<li>差分を考える必要がない</li>
<li>遅い</li>
<li>新しいテーブルを作ると権限(GRANT)を1個1個つけて回る必要があり、面倒</li>
<li>VACUUM問題</li>
</ul>
</li>
<li><p>アトミック洗い替え</p>

<ul>
<li>新しいテーブルを作ってる途中にテーブルが無くなってしまうので、テーブルが作り終わってからTRANSACTION内でALTER TABLE RENAMEする</li>
<li>24時間参照するテーブルではこれを使う</li>
<li>デメリットとしては、データが2倍になってしまう</li>
</ul>
</li>
<li><p>応用：アトミックな本番切り替え</p>

<ul>
<li>複数のテーブルをいっぺんに切り替える</li>
<li>複数のテーブルがお互いにデータが関連している場合</li>
</ul>
</li>
<li><p>更新パターンの使い分け</p>

<ul>
<li>生データは差分更新</li>
<li>中間データは洗い替え</li>
<li>サマリーデータはアトミック洗い替え</li>
</ul>
</li>
</ul>


<h2>なぜRedshiftにしたのか</h2>

<ul>
<li>COOKPADがAWSにあるから</li>
<li>マネージドサービスだから</li>
<li>並列処理能力が高いから</li>
<li>ウィンドウ関数など高度な機能が実装されているから</li>
<li>ある程度オンライン処理にも耐えられるから</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/17/aws-summit-tokyo-2014/">AWS Summit Tokyo 2014: AWSビッグデータサービス Deep Dive</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-17T12:20:00+09:00" pubdate data-updated="true">Jul 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>AWSソリューションアーキテクトのJiang yifengさんによるEMRを中心とした技術の詳説です。</p>

<p>私はまだEMRをヘビーに使ったことはなくて、AWSサービスの中でいうとRedshiftのほうをよく使っています。
ただ、EMRのポテンシャルはとても高く、いま最も使っていきたいサービスの一つです。
他のクラウドサービスに似たサービスが無いことも特徴かと思います。</p>

<p>私が最近EMRに注目しているのは、ずっと起動し続けるサービスではデータが収まりきらなくなってきた、という課題があります。
私が取り組んでいるプロダクトでは、一日に約2TBのログが生まれています。圧縮しても数百GB。そうすると、RDSやRedshift, ElasticSearchなどの起動しっぱなしのクラスタにデータを格納し続けるのが困難になってきました。運用もきついですし、コスト的にもきついです。</p>

<p>そこで、古いデータを消していくという運用になるのですが、後から古いデータにアクセスしたいケースはやはりあります。
また、RedshiftでSQL、というだけではこなせないタスクも想定する必要が出てきたため、EMRを検討しています。</p>

<h3>デザインパターン</h3>

<ul>
<li>一時的なクラスタの活用</li>
<li>ジョブ実行中のみクラスタが存在</li>
<li><p>データはS3に永続化される</p></li>
<li><p>タスクノードの活用</p>

<ul>
<li>Spotインスタンスを使ってコスト削減</li>
<li>短時間で大量のリソースを必要とする場合、S3から大量のデータをHDFSのコピーする際に一時的にタスクノードを追加して、HS1インスタンスなどにデータをロードする手法</li>
</ul>
</li>
</ul>


<h2>ベストプラクティス</h2>

<ul>
<li><p>常に現世代のインスタンスタイプを使用</p></li>
<li><p>ワークロードに最適なノードタイプを選ぶ</p>

<ul>
<li>HS1 HDFS用途</li>
<li>I2 and HS1 ディスクIOが多いジョブ</li>
<li>大きめのノードで構成する小さなクラスタが効率的</li>
</ul>
</li>
<li><p>最適なファイルサイズ</p>

<ul>
<li>小さいファイル(100MB以下)を下げる</li>
<li>S3でHadoop利用の場合は1~2GBが最適なファイルサイズ

<ul>
<li>1mapperからS3のデータ取得速度 10~15mb/s</li>
<li>Mapper処理は60秒以上であるべき 60sec * 15mb = 1GB</li>
</ul>
</li>
<li>S3DistCpを使ってファイルを結合して最適なサイズに。</li>
</ul>
</li>
</ul>


<h2>チューニング</h2>

<ul>
<li><p>最強のチューニングはデータを効率よく保持すること</p></li>
<li><p>Hadoopはバッチ向け</p></li>
<li><p>Hadoop処理時間の目安は1時間〜数日</p></li>
<li><p>短いジョブは他の技術がフィットするかも</p>

<ul>
<li>Apache Storm</li>
<li>Apache Spark</li>
<li>Redshift</li>
</ul>
</li>
<li><p>チューニングについて</p></li>
<li><p>ノード追加！！</p></li>
<li><p>ビジネスの価値を最大化する目的からすると一番早い</p></li>
<li><p>Gangliaでクラスタをモニタリング</p></li>
<li><p>EMRなら1クリックインストール</p></li>
<li><p>例：ネットワークI/O</p>

<ul>
<li>もっとも重要なメトリック。特にS3を使う場合</li>
<li>1つのインスタンスからなるべく多くのネットワークI/Oを引き出す: Mapper数追加</li>
<li>Gangliaでネットワークスループットをチェック例えば200mbpsしか使っていなかったらMapperを追加することで改善する可能性が高い</li>
</ul>
</li>
</ul>


<h2>プラットフォームとしてのEMR</h2>

<h3>HBase</h3>

<ul>
<li><p> 書き込みが激しいものに有効</p></li>
<li><p>OpenTSDB</p>

<ul>
<li>HBase上のtime series database</li>
<li>大規模なモニタリング用</li>
<li>秒間数百万のデータ書き込み</li>
</ul>
</li>
<li><p>自動／手動でAmazon S3にHBaseをバックアップ</p>

<ul>
<li>フルバックアップ／増分バックアップ/指定のバージョンに簡単リストア</li>
</ul>
</li>
</ul>


<h3>Impala</h3>

<ul>
<li>SQL on Hadoop</li>
<li><p>Hiveと互換性が高い: 一部のユースケースにおいてはHiveを置き換えられる</p></li>
<li><p>ストレージレイヤー　永続クラスタのHDFSまたはHbaseを使う必要がある。現時点ではS3に未対応</p></li>
</ul>


<h3>Presto</h3>

<ul>
<li>ブートストラップでインストール</li>
<li>Impalaと違い、S3のデータにダイレクトにアクセス可能なところ</li>
</ul>


<h3>Spark</h3>

<ul>
<li>非常に光速</li>
<li>インメモリで処理しきれるならMapReduceより早いケースが多い</li>
<li>ブートストラップでインストール</li>
<li>ver0.8をサポート。1.0はcoming soon</li>
<li>Sparkはメモリを大量に使う。R3系やSpotインスタンスを利用</li>
<li>CloudWatchでSparkのメトリックスをサポートする JVMの監視が可能</li>
<li>Spark Streaming + Amazon Kinesisの構成でリアルタイムで分散処理</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/18/ubuntu-linux-tutorial-for-centos-user/">CentOSユーザーのためのUbuntu Linux入門(1)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-18T20:12:00+09:00" pubdate data-updated="true">Nov 18<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Ubuntuを使うシチュエーション</h2>

<p>Ubuntuに入門したいCentOSユーザーというのは私自身のことです。</p>

<p>最近、Ubuntu Linuxを使いこなせるようになりたいと思う場面が多いです。
普段はCentOSまたはAmazon Linuxを使っていて、Debian系のUbuntuはおそらく全く使えないということはないのでしょうが、なんとなくハードルを感じてしまうところがあります。</p>

<p>前職では最初Ubuntuを使っているシステムがいくつかあったので、厳密にいうと私が最初にログインしてちょっと触ったLinuxはUbuntuでした。
ただそのときは実質的に何もいじらなかった(ログインしたことあるだけ)ので、ソーシャルゲームを開発することになって、CentOSを本気で触り始めたのが最初です。
それ以来、CentOSばかり使っています。</p>

<p>CentOSを勉強し始めたときは、自分でキューブ型PCを買ってきて、自分の部屋においてセットアップしました。
確かCentOSのイメージを落としてきてDVD-Rか何かに焼いて、それを使ってセットアップした記憶があります。</p>

<p>今Linuxのサーバーを新しく作ろうと思った場合、VirtualBox(Vagrant)やDockerがあるから楽です。
そもそもVagrantやDockerをより深く知りたいがためにUbuntuをやろうと思ったという動機もあります。
chefも（最近少なくなってきましたが）Ubuntuのほうがやりやすい部分があったり、Tizenも現状ではUbuntu前提ですよね。</p>

<p>というわけで、Ubuntuも抵抗感なく普通に使えるほうがよさげなのできちんとさわってみることにしました。　</p>

<h2>バージョンの違いなど</h2>

<p>CentOSだと、いま選ぶのはだいたい5か6系だと思います。
6.4が最新。5.10もStableバージョンで<a href="http://wiki.centos.org/Download">2017年までメンテナンスされる予定</a>ですが、今なら6.4を選んで問題はないでしょう。</p>

<p>Ubuntuのほうですが、<a href="http://www.ubuntulinux.jp/ubuntu">このへんを見るに</a>、12か13系あたりが選択肢になりそうです。
13系はまだ安定バージョンが無いようなので、2017年までサポート予定の12.04(コードネーム：Precise Pangolin)を選んでみることにします。</p>

<p>というわけで、それ用のvagrant boxを追加します。(<a href="http://www.vagrantbox.es">http://www.vagrantbox.es</a> より)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ vagrant box add ubuntu12 http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box</span></code></pre></td></tr></table></div></figure>


<p>CentOSでは32bitのものをi386、64bitのものをx86_64と呼んでいましたが、Ubuntuでは64bitのほうをamd64と呼ぶようですね。　</p>

<p>vagrantでとりあえず起動してみます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Welcome to Ubuntu 12.04.3 LTS (GNU/Linux 3.2.0-56-generic x86_64)
</span><span class='line'>
</span><span class='line'> * Documentation:  https://help.ubuntu.com/
</span><span class='line'>
</span><span class='line'>  System information as of Mon Nov 18 11:44:43 UTC 2013
</span><span class='line'>
</span><span class='line'>  System load:  0.17              Processes:           69
</span><span class='line'>  Usage of /:   2.7% of 39.37GB   Users logged in:     0
</span><span class='line'>  Memory usage: 30%               IP address for eth0: 10.0.2.15
</span><span class='line'>  Swap usage:   0%                IP address for eth1: 192.168.33.11
</span><span class='line'>
</span><span class='line'>  Graph this data and manage this system at https://landscape.canonical.com/
</span><span class='line'>
</span><span class='line'>  Get cloud support with Ubuntu Advantage Cloud Guest:
</span><span class='line'>    http://www.ubuntu.com/business/services/cloud
</span><span class='line'>
</span><span class='line'>  Use Juju to deploy your cloud instances and workloads:
</span><span class='line'>    https://juju.ubuntu.com/#cloud-precise
</span><span class='line'>
</span><span class='line'>0 packages can be updated.
</span><span class='line'>0 updates are security updates.
</span><span class='line'>
</span><span class='line'>_____________________________________________________________________
</span><span class='line'>WARNING! Your environment specifies an invalid locale.
</span><span class='line'> This can affect your user experience significantly, including the
</span><span class='line'> ability to manage packages. You may install the locales by running:
</span><span class='line'>
</span><span class='line'>   sudo apt-get install language-pack-ja
</span><span class='line'>     or
</span><span class='line'>   sudo locale-gen ja_JP.UTF-8
</span><span class='line'>
</span><span class='line'>To see all available language packs, run:
</span><span class='line'>   apt-cache search "^language-pack-[a-z][a-z]$"
</span><span class='line'>To disable this message for all users, run:
</span><span class='line'>   sudo touch /var/lib/cloud/instance/locale-check.skip
</span><span class='line'>_____________________________________________________________________
</span><span class='line'>
</span><span class='line'>vagrant@vagrant-ubuntu-precise-64:~$
</span></code></pre></td></tr></table></div></figure>


<p>いきなり親切なメッセージがいろいろ出てきました。</p>

<p>何かパッケージ入れてみようと思い、apacheはCentOSだとhttpdですがUbuntuはapache2というくらいは知っていたのですがあえてapt-get install httpdとやってみると、</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@vagrant-ubuntu-precise-64:~# apt-get install httpd
</span><span class='line'>Reading package lists... Done
</span><span class='line'>Building dependency tree
</span><span class='line'>Reading state information... Done
</span><span class='line'>Package httpd is a virtual package provided by:
</span><span class='line'>  nginx-naxsi 1.1.19-1ubuntu0.4
</span><span class='line'>  nginx-light 1.1.19-1ubuntu0.4
</span><span class='line'>  nginx-full 1.1.19-1ubuntu0.4
</span><span class='line'>  nginx-extras 1.1.19-1ubuntu0.4
</span><span class='line'>  apache2-mpm-itk 2.2.22-1ubuntu1.4
</span><span class='line'>  apache2-mpm-worker 2.2.22-1ubuntu1.4
</span><span class='line'>  apache2-mpm-prefork 2.2.22-1ubuntu1.4
</span><span class='line'>  apache2-mpm-event 2.2.22-1ubuntu1.4
</span><span class='line'>  yaws 1.92-1
</span><span class='line'>  webfs 1.21+ds1-8
</span><span class='line'>  tntnet 2.0+dfsg1-2
</span><span class='line'>  ocsigen 1.3.4-2build4
</span><span class='line'>  monkey 0.9.3-1ubuntu1
</span><span class='line'>  mini-httpd 1.19-9.2build1
</span><span class='line'>  micro-httpd 20051212-13
</span><span class='line'>  mathopd 1.5p6-1.1
</span><span class='line'>  lighttpd 1.4.28-2ubuntu4
</span><span class='line'>  ebhttpd 1:1.0.dfsg.1-4.2build1
</span><span class='line'>  cherokee 1.2.101-1
</span><span class='line'>  bozohttpd 20100920-1
</span><span class='line'>  boa 0.94.14rc21-3.1
</span><span class='line'>  aolserver4-daemon 4.5.1-15
</span><span class='line'>  aolserver4-core 4.5.1-15
</span><span class='line'>You should explicitly select one to install.
</span><span class='line'>
</span><span class='line'>E: Package 'httpd' has no installation candidate</span></code></pre></td></tr></table></div></figure>


<p>けっこう気が利く感じです。</p>

<p>apache2を入れてみます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@vagrant-ubuntu-precise-64:~# apt-get install apache2
</span><span class='line'>Reading package lists... Done
</span><span class='line'>Building dependency tree
</span><span class='line'>Reading state information... Done
</span><span class='line'>The following extra packages will be installed:
</span><span class='line'>  apache2-mpm-worker apache2-utils apache2.2-bin apache2.2-common libapr1
</span><span class='line'>  libaprutil1 libaprutil1-dbd-sqlite3 libaprutil1-ldap ssl-cert
</span><span class='line'>Suggested packages:
</span><span class='line'>  apache2-doc apache2-suexec apache2-suexec-custom openssl-blacklist
</span><span class='line'>The following NEW packages will be installed:
</span><span class='line'>  apache2 apache2-mpm-worker apache2-utils apache2.2-bin apache2.2-common
</span><span class='line'>  libapr1 libaprutil1 libaprutil1-dbd-sqlite3 libaprutil1-ldap ssl-cert
</span><span class='line'>0 upgraded, 10 newly installed, 0 to remove and 0 not upgraded.
</span><span class='line'>Need to get 1,855 kB of archives.
</span><span class='line'>After this operation, 5,681 kB of additional disk space will be used.
</span><span class='line'>Do you want to continue [Y/n]? y
</span><span class='line'>Get:1 http://archive.ubuntu.com/ubuntu/ precise/main libapr1 amd64 1.4.6-1 [89.6 kB]
</span><span class='line'>Get:2 http://archive.ubuntu.com/ubuntu/ precise/main libaprutil1 amd64 1.3.12+dfsg-3 [74.6 kB]
</span><span class='line'>Get:3 http://archive.ubuntu.com/ubuntu/ precise/main libaprutil1-dbd-sqlite3 amd64 1.3.12+dfsg-3 [10.4 kB]
</span><span class='line'>Get:4 http://archive.ubuntu.com/ubuntu/ precise/main libaprutil1-ldap amd64 1.3.12+dfsg-3 [8,044 B]
</span><span class='line'>Get:5 http://archive.ubuntu.com/ubuntu/ precise-updates/main apache2.2-bin amd64 2.2.22-1ubuntu1.4 [1,340 kB]
</span><span class='line'>Get:6 http://archive.ubuntu.com/ubuntu/ precise-updates/main apache2-utils amd64 2.2.22-1ubuntu1.4 [90.1 kB]
</span><span class='line'>Get:7 http://archive.ubuntu.com/ubuntu/ precise-updates/main apache2.2-common amd64 2.2.22-1ubuntu1.4 [226 kB]
</span><span class='line'>Get:8 http://archive.ubuntu.com/ubuntu/ precise-updates/main apache2-mpm-worker amd64 2.2.22-1ubuntu1.4 [2,284 B]
</span><span class='line'>Get:9 http://archive.ubuntu.com/ubuntu/ precise-updates/main apache2 amd64 2.2.22-1ubuntu1.4 [1,492 B]
</span><span class='line'>Get:10 http://archive.ubuntu.com/ubuntu/ precise-updates/main ssl-cert all 1.0.28ubuntu0.1 [12.3 kB]
</span><span class='line'>Fetched 1,855 kB in 7s (236 kB/s)
</span><span class='line'>Preconfiguring packages ...
</span><span class='line'>Selecting previously unselected package libapr1.
</span><span class='line'>(Reading database ... 61149 files and directories currently installed.)
</span><span class='line'>Unpacking libapr1 (from .../libapr1_1.4.6-1_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package libaprutil1.
</span><span class='line'>Unpacking libaprutil1 (from .../libaprutil1_1.3.12+dfsg-3_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package libaprutil1-dbd-sqlite3.
</span><span class='line'>Unpacking libaprutil1-dbd-sqlite3 (from .../libaprutil1-dbd-sqlite3_1.3.12+dfsg-3_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package libaprutil1-ldap.
</span><span class='line'>Unpacking libaprutil1-ldap (from .../libaprutil1-ldap_1.3.12+dfsg-3_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package apache2.2-bin.
</span><span class='line'>Unpacking apache2.2-bin (from .../apache2.2-bin_2.2.22-1ubuntu1.4_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package apache2-utils.
</span><span class='line'>Unpacking apache2-utils (from .../apache2-utils_2.2.22-1ubuntu1.4_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package apache2.2-common.
</span><span class='line'>Unpacking apache2.2-common (from .../apache2.2-common_2.2.22-1ubuntu1.4_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package apache2-mpm-worker.
</span><span class='line'>Unpacking apache2-mpm-worker (from .../apache2-mpm-worker_2.2.22-1ubuntu1.4_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package apache2.
</span><span class='line'>Unpacking apache2 (from .../apache2_2.2.22-1ubuntu1.4_amd64.deb) ...
</span><span class='line'>Selecting previously unselected package ssl-cert.
</span><span class='line'>Unpacking ssl-cert (from .../ssl-cert_1.0.28ubuntu0.1_all.deb) ...
</span><span class='line'>Processing triggers for man-db ...
</span><span class='line'>Processing triggers for ureadahead ...
</span><span class='line'>Processing triggers for ufw ...
</span><span class='line'>Setting up libapr1 (1.4.6-1) ...
</span><span class='line'>Setting up libaprutil1 (1.3.12+dfsg-3) ...
</span><span class='line'>Setting up libaprutil1-dbd-sqlite3 (1.3.12+dfsg-3) ...
</span><span class='line'>Setting up libaprutil1-ldap (1.3.12+dfsg-3) ...
</span><span class='line'>Setting up apache2.2-bin (2.2.22-1ubuntu1.4) ...
</span><span class='line'>Setting up apache2-utils (2.2.22-1ubuntu1.4) ...
</span><span class='line'>Setting up apache2.2-common (2.2.22-1ubuntu1.4) ...
</span><span class='line'>Enabling site default.
</span><span class='line'>Enabling module alias.
</span><span class='line'>Enabling module autoindex.
</span><span class='line'>Enabling module dir.
</span><span class='line'>Enabling module env.
</span><span class='line'>Enabling module mime.
</span><span class='line'>Enabling module negotiation.
</span><span class='line'>Enabling module setenvif.
</span><span class='line'>Enabling module status.
</span><span class='line'>Enabling module auth_basic.
</span><span class='line'>Enabling module deflate.
</span><span class='line'>Enabling module authz_default.
</span><span class='line'>Enabling module authz_user.
</span><span class='line'>Enabling module authz_groupfile.
</span><span class='line'>Enabling module authn_file.
</span><span class='line'>Enabling module authz_host.
</span><span class='line'>Enabling module reqtimeout.
</span><span class='line'>Setting up apache2-mpm-worker (2.2.22-1ubuntu1.4) ...
</span><span class='line'> * Starting web server apache2                                                                                              apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1 for ServerName
</span><span class='line'>                                                                                                                     [ OK ]
</span><span class='line'>Setting up apache2 (2.2.22-1ubuntu1.4) ...
</span><span class='line'>Setting up ssl-cert (1.0.28ubuntu0.1) ...
</span><span class='line'>Processing triggers for libc-bin ...
</span><span class='line'>ldconfig deferred processing now taking place
</span></code></pre></td></tr></table></div></figure>


<p>どうやらworkerのmpmだけがインストールされ、さらにapacheが勝手に起動しました(；´Д｀)
パッケージ入れただけなのに。。。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@vagrant-ubuntu-precise-64:~# /etc/init.d/apache2 status
</span><span class='line'>Apache2 is running (pid 2595).</span></code></pre></td></tr></table></div></figure>


<p>いきなり勝手が違っててもやもやしてきたわけですが、続く。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/18/web-api-hackathon-3-backlog-kanban/">Web Api Hackathon Vol.3 というイベントで「Backlog Kanban」というウェブアプリを作成しました</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-18T16:23:00+09:00" pubdate data-updated="true">Nov 18<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Web Api Hackathon Vol.3</h2>

<p>2013/11/17に行われた、<a href="http://connpass.com/series/533/">Web Api Hackathon</a>に行ってきました。私は初参加でしたが、もう3回目で、とりあえずWeb Api叩いて何か作ろうというざっくりしたテーマで行うハッカソン形式のイベントです。
<a href="http://ma9.mashupaward.jp/">Mashup Award</a>のコンセプトにも近いですね。</p>

<p>場所はお台場にある<a href="http://www.members.co.jp/company/access.html">Membersさんのオフィス</a>のラウンジ。机やお座敷やソファのあるかなり大きなスペースで、中央には大きなプロジェクタがあって、裏の隠れたところに昼寝スペースという、個人的にはかなりお気に入りのスペースでした。
リラックマの超大きなぬいぐるみがあったのも印象的でした(写真撮影NGだったのが残念・・・)。</p>

<h2>Backlog Kanban &ndash; カンバン形式でBacklogのプロジェクトを見る</h2>

<p><a href="http://www.backlog.jp">Backlog</a> というプロジェクト管理ツールがあって、仕事でも利用しています。
1プロジェクト、10人までは無料で使えるので、個人プロジェクトにも利用しています。
このウェブサービスは、ポップなデザインと使いやすいインタフェース、メールに直接返信で課題が更新される、などなどでとても良いサービスなのですが、一点不満があって、それはプロジェクトの概観をしづらいということでした。</p>

<p>なのでこれまではBacklogとは別に、ホワイトボードにポストイットを貼って管理していました。（<a href="http://www.infoq.com/jp/articles/agile-kanban-boards">こういうイメージ</a> ）
ただ、これをBacklogで直接やれたらいいのにとつねづね思っていました。</p>

<p>そこで、それを今回のハッカソンで作ってみようと思いたち、そうしてできたのがこちらです。</p>

<h3>Backlog Kanban(デモサイト)</h3>

<p><a href="http://kanban.kirishikistudios.com/">http://kanban.kirishikistudios.com/</a></p>

<h3>ソース(GitHub)</h3>

<p><a href="https://github.com/backlog-kanban/backlog-kanban">https://github.com/backlog-kanban/backlog-kanban</a></p>

<p><img src="/images/2013-11-17-backlog-kanban.png" alt="backlog-kanban" /></p>

<p>できたというか、まだ全くの開発途中ですが、一応カンバン形式で閲覧するツールとしては動作しています。</p>

<p><a href="http://www.backlog.jp/api/">Backlog API</a> を使って課題の一覧を取得し、新しいUIに落としただけ、という簡単なものですが、「これがやりたかったんだよ！！」というのができた気がします。</p>

<p>「スケジュールが過ぎたものは赤色で表示される」「課題の種別によって色分け」「課題をクリックするとBacklog本体の課題のぺーじに飛ぶ」などの機能があります。もちろん、Backlog本体側を更新すればその内容はこちらに即座に反映されます。</p>

<p>使った技術はこちら。</p>

<ul>
<li>Amazon EC2 (Amazon Linux, micro instance)</li>
<li>Ruby 2.0</li>
<li>Ruby on Rails 4.0.1</li>
<li>rbenv</li>
<li>apache + passenger</li>
</ul>


<p>プレゼン資料はこちら。</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/28331762" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/mima_v/20131117-backlog-kanban" title="20131117 backlog kanban【第３回Web API ハッカソン】" target="_blank">20131117 backlog kanban【第３回Web API ハッカソン】</a> </strong> from <strong><a href="http://www.slideshare.net/mima_v" target="_blank">Marie Suenaga</a></strong> </div></p>

<p>今後は、</p>

<ul>
<li>Backlogアカウントによるログインと閲覧の認証</li>
<li>課題の追加・編集機能</li>
<li>カテゴリや種別の追加・変更への対応</li>
</ul>


<p>などができるとよいと思います。</p>

<h2>デザイン・フロント・サーバーの3人で開発してみて</h2>

<p>ハッカソンで、初対面の人たち同士でアプリを作るということをこれまで何回かやってきましたが、本当に難しいと思います。
各メンバーのスキルセットを理解して、何のツールなら熟知しているのか、どこの部分で境界線を引いて分担するのが良いのか、など。
そもそも作りたいものが一致しているのかもすり合わせないといけません。</p>

<p>今回チームを作ったのは3人ですが、みな初対面。
その場で自己紹介をして、基本的な開発手法について議論と相談をして、どう作業するかを決めていきました。</p>

<p>役割分担はこんな感じ。</p>

<ul>
<li><a href="https://github.com/mima-v">@mima-v</a> 全体デザイン、画像制作</li>
<li><a href="https://github.com/oogushitakuya">@oogushitakuya</a> フロント部分(HTML,JavaScriptのコーディング)</li>
<li><a href="https://github.com/chokkoyamada">@chokkoyamada</a> サーバーサイド(Railsを使ったBacklogAPIの操作、公開用サーバー設定)</li>
</ul>


<p>アイデア段階から実際のアプリ作成まで8時間弱で、何かできるか不安でしたが、各メンバーがGitHubを使ったワークフローをわかっていたおかげでスムーズに作業が進んだと思います。</p>

<h2>作ったアプリを公開する場所があったらいい</h2>

<p>Railsに限らずですが、何かアプリを作ったときにそれをグローバルに無料で公開できる場所が少ないなと思いました。
Railsだと有名なのはHerokuですが、PostgreSQLなのがネックだし、他にも選択肢があると良いと思います。</p>

<p>今回は結局AWSでMicroインスタンスを立ててそこにapache入れてpassenger入れて・・・とやったのですが、Microインスタンスにしてもこの１アプリだけを置いておくにはもったいないです。
今後また別のRailsアプリを作ったらこのインスタンスにデプロイしていきたいと思います。</p>

<h3>参考リンク</h3>

<p>WebAPI Hackathon | デザイナー/コーダーとエンジニアが集まってWeb APIを使ってなにかを作る会  <a href="http://webapi-hackathon.info/">http://webapi-hackathon.info/</a></p>

<p>Web Api Hackathon Vol.3 &ndash; connpass  <a href="http://connpass.com/event/3890/">http://connpass.com/event/3890/</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/06/21/dell-infra-seminar/">Dell主催「次世代ネットサービス向け クラウド・インフラストラクチャ セミナー」- プライベートクラウドについて考える</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-06-21T14:56:00+09:00" pubdate data-updated="true">Jun 21<span>st</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>2013/06/21 15:00~18:00、<a href="http://www.event-reg.jp/dell/sem130621/">デル株式会社主催『次世代ネットサービス向け クラウド・インフラストラクチャ セミナー』</a>というセミナーが行われたので参加しました。Dellもクラウドのセミナーをやるようになったとは時代の流れを感じます。</p>

<p>前半2つのセッションはほとんど聴いていなかったので、後半2つのセッションについて書き留めておきます。</p>

<h2>『WEBサービスに最適なクラウド基盤を構成する３つの要素』(クリエーションライン：安田さん)</h2>

<p><a href="http://www.creationline.com">クリエーションライン</a> という会社、Opscode Chefの日本の正規代理店という点で名前だけは知っていましたが、今回はじめて具体的に業務内容を知りました。</p>

<p>クラウドの導入支援やコンサルティングをしている会社なんですね。OpenStack周りでコミュニティとも関わりの強い会社のようです。</p>

<p>タイトルにある3つの要素とは、下記の3点のことで、ぞれぞれについて解説が行われました。</p>

<ul>
<li>プラットフォーム・・・パブリッククラウドか、プライベートクラウドか</li>
<li>構成管理(自動化)・・・Opscode Chefを使う</li>
<li>マネジメント(マルチクラウド)・・・<a href="http://www.enstratius.com">Enstratius</a>を使う</li>
</ul>


<p>パブリッククラウドかプライベートクラウドかについては、今回のセミナーはDellのクラウド関係ということで、プライベートクラウドに焦点が当たっていましたが、サービスやチームの性質や規模によってケースバイケースなので、決まった答えはないのかなと思いました。</p>

<p>構成管理ツールについては、私はChef一択ということはないと思っています。Chefは非常に多機能でマルチプラットフォーム対応が柔軟なぶん、やや複雑化しすぎてしまっていると思います。かといってPuppetの勢いはそれほど無いし、またはAnsibleやSaltやCuisineなのかというとそうでも無い気がしています。
言語やDSLがどうというより、「RedHat系Linuxに特化」などある程度OSを絞った形でやらないとchefでいうcookbookのメンテが無理すぎる、というのがchefを1年ほどさわって抱いた感想です。</p>

<h2>サイバーエージェントにおけるプライベートクラウド本格導入～その実情(サイバーエージェント：奈良さん)</h2>

<p>サイバーエージェント本体のインフラ部門が構築中のプライベートクラウドの内部の解説でした。実際の管理画面やネットワーク図などを含んだ詳細な解説がありました。</p>

<p>とにかく開発スピードの高速化に貢献できるプライベートクラウドを目指すという目的のもと、機能的なメリットよりはシンプルさを追求したものになっています。ディスク以外は冗長化をなるべくせず、アプリケーション側でフェイルオーバーを前提とした作りにするというくだりが印象的でした。</p>

<p>私はこれまで海外事業をやってきたのでこのプライベートクラウドを使う機会は無かったのですが、一応アカウントがあって管理画面入ってみたり仮想サーバーを作ってみたことはあります。</p>

<p>中途半端に中を知っているだけにコメントしづらいのですが、全社的にインフラを共有して効率化とコスト削減を狙うという基本姿勢は大賛成だしその方向でうまくいっていると思います。</p>

<p>AWSと比較されることが多いそうですが、多機能、複雑なAWSに対してとことんシンプルさを追求するサイバーエージェントのプライベートクラウドは、うまく棲み分けできると思います。</p>

<p>ただ独自路線を突き進むよりは、コミュニティ、たとえばOpenStackに追従したほうがいいと思います(ぼそっ</p>

<h2>Juju &ndash; Ubuntuのクラウドのオーケストレーションツール</h2>

<p>セミナーのセッションとは直接関係がないのですが、終わった後の懇親会で、Ubuntuの支援企業であるCanonicalの人が面白いツールを教えてくれました。</p>

<p>Juju<br/>
<a href="https://juju.ubuntu.com/">https://juju.ubuntu.com/</a></p>

<p>オーケストレーションツール(Orchestration Tool)といわれるツールです。</p>

<p>私はUbuntuは使っていないのですが、chefのcookbookがUbuntuベースで作られていることが多いので、Ubuntuを使えば簡単なのにと思うことはたまにあります。その話を振ってみたところ、Jujuの話がでてきました。オーケストレーションツールはchefのような構成管理ツールと同等には重要な存在になると思うのですが、まだ定番といえるものが出てきていません。今後ぜひ調べてみたいと思います。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/06/21/fabric-reverse-dictionary-1/">逆引きFabric(1)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-06-21T08:33:00+09:00" pubdate data-updated="true">Jun 21<span>st</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>環境を整える</h2>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/07/18/aws-summit-tokyo-2014-kinesis-deep-dive/">AWS Summit Tokyo 2014: Amazon Kinesis Deep Dive</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/07/18/aws-summit-tokyo-2014-dynamo-kinesis/">AWS Summit Tokyo 2014: Amazon Kinesisを用いたリアルタイムのゲーム分析システムと、AWS ElasticBeanstalk＆Amazon DynamoDB を活用したゲーム運営</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/07/18/aws-summit-tokyo-2014-grani-windows/">AWS Summit Tokyo 2014: AWS + Windows(C#)で構築する.NET最先端技術によるハイパフォーマンスウェブアプリケーション開発実践</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/07/18/aws-summit-tokyo-2014-cloudfront/">AWS Summit Tokyo 2014: Amazon CloudFrontを利用したサイト高速化およびセキュア配信</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/07/17/aws-summit-tokyo-2014-redshift-realtime-cookpad/">AWS Summit Tokyo 2014: Amazon Redshiftによるリアルタイム分析サービスの構築</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/chokkoyamada">@chokkoyamada</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'chokkoyamada',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Naoyuki Yamada -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
